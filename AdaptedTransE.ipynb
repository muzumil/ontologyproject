{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTv7JQyx2X3P",
        "outputId": "9ed7ee81-c45c-4973-f7d5-bb474f9ddbf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.13.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2025.11.12)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.7.0\n",
            "Environment setup complete. Folders created.\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Setup and Dependencies\n",
        "\n",
        "# Install necessary libraries\n",
        "!pip install pandas numpy torch torch_geometric tqdm\n",
        "\n",
        "# --- Create required directories ---\n",
        "# The scripts assume these folders exist for input files.\n",
        "import os\n",
        "os.makedirs(\"vocab\", exist_ok=True)\n",
        "os.makedirs(\"SnomedCT/Snapshot/Terminology\", exist_ok=True)\n",
        "\n",
        "print(\"Environment setup complete. Folders created.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BInw6Yr_g_yK",
        "outputId": "40fb5070-96fd-4d0e-9776-296b1bda0728"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Google Drive mounted. Please ensure your data files are in '/content/drive/MyDrive/knowledgegraphdata' and update relevant paths in subsequent cells.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- User Configuration: Set your base path for data on Google Drive ---\n",
        "# Make sure your files are organized relative to this path, matching the original structure.\n",
        "# Example: If 'mimic-iv-3.1' is in 'MyDrive/KnowledgeGraphData/', set path below.\n",
        "BASE_DRIVE_PATH = '/content/drive/MyDrive/knowledgegraphdata'\n",
        "\n",
        "# --- Placeholder creation removed ---\n",
        "# You should place your actual data files in your Google Drive\n",
        "# under the structure:\n",
        "# {BASE_DRIVE_PATH}/mimic-iv-3.1/hosp/diagnoses_icd.csv.gz\n",
        "# {BASE_DRIVE_PATH}/vocab/CONCEPT.zip\n",
        "# {BASE_DRIVE_PATH}/vocab/CONCEPT_RELATIONSHIP.zip\n",
        "# {BASE_DRIVE_PATH}/SnomedCT/Snapshot/Terminology/sct2_Relationship_Snapshot_US1000124_20250901.txt\n",
        "# {BASE_DRIVE_PATH}/SnomedCT/Snapshot/Terminology/sct2_Description_Snapshot-en_US1000124_20250901.txt\n",
        "\n",
        "print(f\"Google Drive mounted. Please ensure your data files are in '{BASE_DRIVE_PATH}' and update relevant paths in subsequent cells.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTHqVyZgF0Kb",
        "outputId": "4cce12e1-5680-47e1-fd44-360c93fcb04d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Loading SNOMED CT raw files...\n",
            "→ Relationships: (3581598, 10), Descriptions: (1696627, 9)\n",
            " Active filter: 3,581,598 → 1,336,381 (removed 2,245,217)\n",
            " Preferred terms: 1,696,627 → 994,002 (removed 702,625)\n",
            " Found 101 unique SNOMED relation types\n",
            "\n",
            " Merging concept names...\n",
            "→ Merge completed: (1336381, 11) → (7161453, 13)\n",
            "\n",
            " Cleaning data...\n",
            "Removed empty rows: 1\n",
            "Removed blank-term rows: 0\n",
            "\n",
            "====== SUMMARY REPORT ======\n",
            "Final dataset shape: (7161452, 5)\n",
            "Saved to: snomed_relations_full.tsv\n",
            "  sourceId                                                               source_term   relation_term destinationId      destination_term\n",
            "1231766002                                     Hemorrhage after thrombolytic therapy            Is a     131148009           Haemorrhage\n",
            "  27520001                                 Pustular psoriasis of the palms and soles      Morphology      48055004         Pustular rash\n",
            " 766940004                                                                      Role            Is a     362981000       Qualifier value\n",
            " 735516004                              Gonococcal infection of genitourinary system Causative agent      68704007            Gonococcus\n",
            " 776416004 Hyperuricaemia, pulmonary hypertension, renal failure, alkalosis syndrome            Is a      90688005 Chronic renal failure\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# === File paths ===\n",
        "# Use BASE_DRIVE_PATH for Google Drive files\n",
        "rels_path = os.path.join(BASE_DRIVE_PATH, \"/content/drive/MyDrive/knowledgegraphdata/sct2_Relationship_Snapshot_US1000124_20250901.txt\")\n",
        "desc_path = os.path.join(BASE_DRIVE_PATH, \"/content/drive/MyDrive/knowledgegraphdata/sct2_Description_Snapshot-en_US1000124_20250901.txt\")\n",
        "\n",
        "print(\"\\n Loading SNOMED CT raw files...\")\n",
        "snomed_rels = pd.read_csv(rels_path, sep=\"\\t\", dtype=str)\n",
        "snomed_descs = pd.read_csv(desc_path, sep=\"\\t\", dtype=str)\n",
        "print(f\"\\u2192 Relationships: {snomed_rels.shape}, Descriptions: {snomed_descs.shape}\")\n",
        "\n",
        "# ===  Keep only active relationships ===\n",
        "before_active = len(snomed_rels)\n",
        "snomed_rels = snomed_rels[snomed_rels[\"active\"] == \"1\"]\n",
        "after_active = len(snomed_rels)\n",
        "print(f\" Active filter: {before_active:,} \\u2192 {after_active:,} (removed {before_active - after_active:,})\")\n",
        "\n",
        "# ===  Extract preferred terms ===\n",
        "before_pref = len(snomed_descs)\n",
        "pref_terms = snomed_descs[snomed_descs[\"typeId\"] == \"900000000000013009\"][[\"conceptId\", \"term\"]]\n",
        "pref_terms.dropna(subset=[\"term\"], inplace=True)\n",
        "after_pref = len(pref_terms)\n",
        "print(f\" Preferred terms: {before_pref:,} \\u2192 {after_pref:,} (removed {before_pref - after_pref:,})\")\n",
        "\n",
        "# ===  Build full relation map (typeId \\u2192 term) ===\n",
        "relation_ids = snomed_rels[\"typeId\"].unique()\n",
        "relation_map_df = pref_terms[pref_terms[\"conceptId\"].isin(relation_ids)]\n",
        "relation_map = dict(zip(relation_map_df[\"conceptId\"], relation_map_df[\"term\"]))\n",
        "print(f\" Found {len(relation_map)} unique SNOMED relation types\")\n",
        "\n",
        "# === Add human-readable relation names ===\n",
        "snomed_rels[\"relation_term\"] = snomed_rels[\"typeId\"].map(relation_map).fillna(\"other_relation\")\n",
        "\n",
        "# ===  Merge source & destination names ===\n",
        "print(\"\\n Merging concept names...\")\n",
        "rels_before_merge = snomed_rels.shape\n",
        "\n",
        "snomed_rels = snomed_rels.merge(\n",
        "    pref_terms, left_on=\"sourceId\", right_on=\"conceptId\", how=\"left\"\n",
        ").rename(columns={\"term\": \"source_term\"}).drop(columns=[\"conceptId\"])\n",
        "\n",
        "snomed_rels = snomed_rels.merge(\n",
        "    pref_terms, left_on=\"destinationId\", right_on=\"conceptId\", how=\"left\"\n",
        ").rename(columns={\"term\": \"destination_term\"}).drop(columns=[\"conceptId\"])\n",
        "\n",
        "rels_after_merge = snomed_rels.shape\n",
        "print(f\"\\u2192 Merge completed: {rels_before_merge} \\u2192 {rels_after_merge}\")\n",
        "\n",
        "print(\"\\n Cleaning data...\")\n",
        "before_clean = len(snomed_rels)\n",
        "\n",
        "# Drop empty fields\n",
        "snomed_rels = snomed_rels.dropna(subset=[\"source_term\", \"destination_term\", \"relation_term\"])\n",
        "after_dropna = len(snomed_rels)\n",
        "print(f\"Removed empty rows: {before_clean - after_dropna:,}\")\n",
        "\n",
        "# Drop rows with blank strings\n",
        "mask_blank = ((snomed_rels[\"source_term\"].str.strip() == \"\") |  (snomed_rels[\"destination_term\"].str.strip() == \"\"))\n",
        "removed_blank = mask_blank.sum()\n",
        "snomed_rels = snomed_rels[~mask_blank]\n",
        "print(f\"Removed blank-term rows: {removed_blank:,}\")\n",
        "\n",
        "\n",
        "# Reorder columns\n",
        "snomed_rels = snomed_rels[[\"sourceId\", \"source_term\", \"relation_term\", \"destinationId\", \"destination_term\"]]\n",
        "\n",
        "#Save final dataset\n",
        "out_path = \"snomed_relations_full.tsv\"\n",
        "snomed_rels.to_csv(out_path, sep=\"\\t\", index=False)\n",
        "\n",
        "#Summary report\n",
        "print(\"\\n====== SUMMARY REPORT ======\")\n",
        "print(f\"Final dataset shape: {snomed_rels.shape}\")\n",
        "print(f\"Saved to: {out_path}\")\n",
        "print(snomed_rels.sample(min(5, len(snomed_rels)), random_state=42).to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c8940d7f",
        "outputId": "21f3f54c-48be-4d3e-9498-f0a066753199"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading MIMIC-IV diagnoses data...\n",
            "Loaded: 6,364,488 rows × 5 columns\n",
            "\n",
            "ICD-10 filter applied: 6,364,488 → 3,455,747 rows\n",
            "Cleaned empty ICD codes: 3,455,747 → 3,455,747 rows\n",
            "Removed duplicates: 58\n",
            "\n",
            "Cleaned ICD-10 data saved → mimic_icd10_clean.csv\n",
            "\n",
            "Sample of cleaned dataset:\n",
            "subject_id  hadm_id seq_num icd_code icd_version\n",
            "  11979534 27415150       5     N185          10\n",
            "  11130556 28389443       8   F10239          10\n",
            "  16475227 21680259      14     M353          10\n",
            "  19645775 21606532       8    J9811          10\n",
            "  12448853 22437295       2    K5289          10\n",
            "  13847788 27562694      10  T17590A          10\n",
            "  19368574 29840211       7     M109          10\n",
            "  12833439 22586352      12   Z87891          10\n",
            "  19655369 27157385       8    Z9884          10\n",
            "  15221512 29743103      11    I5021          10\n",
            "\n",
            "Loading OHDSI Athena vocabularies...\n",
            "Loaded CONCEPT.csv from /content/drive/MyDrive/knowledgegraphdata/CONCEPT.zip\n",
            "Loaded CONCEPT_RELATIONSHIP.csv from /content/drive/MyDrive/knowledgegraphdata/CONCEPT_RELATIONSHIP.zip\n",
            "Concepts: 5,040,897 rows, Relationships: 36,862,206 rows\n",
            "\n",
            "--- Debug: concepts DataFrame head ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  concept_id                             concept_name domain_id vocabulary_id  \\\n",
              "0   45756805                     Pediatric Cardiology  Provider          ABMS   \n",
              "1   45756804                 Pediatric Anesthesiology  Provider          ABMS   \n",
              "2   45756803  Pathology-Anatomic / Pathology-Clinical  Provider          ABMS   \n",
              "3   45756802                    Pathology - Pediatric  Provider          ABMS   \n",
              "4   45756801            Pathology - Molecular Genetic  Provider          ABMS   \n",
              "\n",
              "      concept_class_id standard_concept concept_code valid_start_date  \\\n",
              "0  Physician Specialty                S  OMOP4821938         19700101   \n",
              "1  Physician Specialty                S  OMOP4821939         19700101   \n",
              "2  Physician Specialty                S  OMOP4821940         19700101   \n",
              "3  Physician Specialty                S  OMOP4821941         19700101   \n",
              "4  Physician Specialty                S  OMOP4821942         19700101   \n",
              "\n",
              "  valid_end_date invalid_reason  \n",
              "0       20991231            NaN  \n",
              "1       20991231            NaN  \n",
              "2       20991231            NaN  \n",
              "3       20991231            NaN  \n",
              "4       20991231            NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9cfd304e-0828-4940-b8e5-95ceb954e14d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>concept_id</th>\n",
              "      <th>concept_name</th>\n",
              "      <th>domain_id</th>\n",
              "      <th>vocabulary_id</th>\n",
              "      <th>concept_class_id</th>\n",
              "      <th>standard_concept</th>\n",
              "      <th>concept_code</th>\n",
              "      <th>valid_start_date</th>\n",
              "      <th>valid_end_date</th>\n",
              "      <th>invalid_reason</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>45756805</td>\n",
              "      <td>Pediatric Cardiology</td>\n",
              "      <td>Provider</td>\n",
              "      <td>ABMS</td>\n",
              "      <td>Physician Specialty</td>\n",
              "      <td>S</td>\n",
              "      <td>OMOP4821938</td>\n",
              "      <td>19700101</td>\n",
              "      <td>20991231</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>45756804</td>\n",
              "      <td>Pediatric Anesthesiology</td>\n",
              "      <td>Provider</td>\n",
              "      <td>ABMS</td>\n",
              "      <td>Physician Specialty</td>\n",
              "      <td>S</td>\n",
              "      <td>OMOP4821939</td>\n",
              "      <td>19700101</td>\n",
              "      <td>20991231</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>45756803</td>\n",
              "      <td>Pathology-Anatomic / Pathology-Clinical</td>\n",
              "      <td>Provider</td>\n",
              "      <td>ABMS</td>\n",
              "      <td>Physician Specialty</td>\n",
              "      <td>S</td>\n",
              "      <td>OMOP4821940</td>\n",
              "      <td>19700101</td>\n",
              "      <td>20991231</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>45756802</td>\n",
              "      <td>Pathology - Pediatric</td>\n",
              "      <td>Provider</td>\n",
              "      <td>ABMS</td>\n",
              "      <td>Physician Specialty</td>\n",
              "      <td>S</td>\n",
              "      <td>OMOP4821941</td>\n",
              "      <td>19700101</td>\n",
              "      <td>20991231</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>45756801</td>\n",
              "      <td>Pathology - Molecular Genetic</td>\n",
              "      <td>Provider</td>\n",
              "      <td>ABMS</td>\n",
              "      <td>Physician Specialty</td>\n",
              "      <td>S</td>\n",
              "      <td>OMOP4821942</td>\n",
              "      <td>19700101</td>\n",
              "      <td>20991231</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9cfd304e-0828-4940-b8e5-95ceb954e14d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9cfd304e-0828-4940-b8e5-95ceb954e14d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9cfd304e-0828-4940-b8e5-95ceb954e14d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-dc5bde4f-609e-4027-a864-85ccf1a8da53\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dc5bde4f-609e-4027-a864-85ccf1a8da53')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-dc5bde4f-609e-4027-a864-85ccf1a8da53 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Debug: rels DataFrame head ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  concept_id_1 concept_id_2      relationship_id valid_start_date  \\\n",
              "0     19082573     36935620  RxNorm dose form of         20230522   \n",
              "1     40703384     36962214    Has marketed form         20230522   \n",
              "2     19082573     36939166  RxNorm dose form of         20230522   \n",
              "3     19001949     36946096  RxNorm dose form of         20230522   \n",
              "4     19082573     36942470  RxNorm dose form of         20230522   \n",
              "\n",
              "  valid_end_date invalid_reason  \n",
              "0       20991231            NaN  \n",
              "1       20991231            NaN  \n",
              "2       20991231            NaN  \n",
              "3       20991231            NaN  \n",
              "4       20991231            NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3cf4173b-0b46-4daa-8485-dc372bb025ea\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>concept_id_1</th>\n",
              "      <th>concept_id_2</th>\n",
              "      <th>relationship_id</th>\n",
              "      <th>valid_start_date</th>\n",
              "      <th>valid_end_date</th>\n",
              "      <th>invalid_reason</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19082573</td>\n",
              "      <td>36935620</td>\n",
              "      <td>RxNorm dose form of</td>\n",
              "      <td>20230522</td>\n",
              "      <td>20991231</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>40703384</td>\n",
              "      <td>36962214</td>\n",
              "      <td>Has marketed form</td>\n",
              "      <td>20230522</td>\n",
              "      <td>20991231</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19082573</td>\n",
              "      <td>36939166</td>\n",
              "      <td>RxNorm dose form of</td>\n",
              "      <td>20230522</td>\n",
              "      <td>20991231</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>19001949</td>\n",
              "      <td>36946096</td>\n",
              "      <td>RxNorm dose form of</td>\n",
              "      <td>20230522</td>\n",
              "      <td>20991231</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19082573</td>\n",
              "      <td>36942470</td>\n",
              "      <td>RxNorm dose form of</td>\n",
              "      <td>20230522</td>\n",
              "      <td>20991231</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3cf4173b-0b46-4daa-8485-dc372bb025ea')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3cf4173b-0b46-4daa-8485-dc372bb025ea button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3cf4173b-0b46-4daa-8485-dc372bb025ea');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-bdbdee9b-64a1-44d8-92b9-8d582ddac07e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bdbdee9b-64a1-44d8-92b9-8d582ddac07e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-bdbdee9b-64a1-44d8-92b9-8d582ddac07e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Debug: merged DataFrame head (relevant columns) ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  concept_code_source vocabulary_id_source concept_id_2  \\\n",
              "0         OMOP5199592     RxNorm Extension     36919314   \n",
              "1         OMOP5212221     RxNorm Extension     36919391   \n",
              "2         OMOP5208019     RxNorm Extension     36919422   \n",
              "3         OMOP5185964     RxNorm Extension     36919439   \n",
              "4         OMOP5191160     RxNorm Extension     36919440   \n",
              "\n",
              "                            concept_name_destination vocabulary_id_destination  \n",
              "0                             Tozinameran 0.05 MG/ML          RxNorm Extension  \n",
              "1  100 ML amoxicillin 25 MG/ML / clavulanate 6.25...          RxNorm Extension  \n",
              "2  0.8 ML adalimumab 50 MG/ML Injectable Solution...          RxNorm Extension  \n",
              "3  ondansetron 8 MG Disintegrating Oral Tablet by...          RxNorm Extension  \n",
              "4  tadalafil 10 MG Delayed Release Oral Tablet Bo...          RxNorm Extension  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-537d1ab0-0648-4260-8977-21efddb1e92c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>concept_code_source</th>\n",
              "      <th>vocabulary_id_source</th>\n",
              "      <th>concept_id_2</th>\n",
              "      <th>concept_name_destination</th>\n",
              "      <th>vocabulary_id_destination</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OMOP5199592</td>\n",
              "      <td>RxNorm Extension</td>\n",
              "      <td>36919314</td>\n",
              "      <td>Tozinameran 0.05 MG/ML</td>\n",
              "      <td>RxNorm Extension</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>OMOP5212221</td>\n",
              "      <td>RxNorm Extension</td>\n",
              "      <td>36919391</td>\n",
              "      <td>100 ML amoxicillin 25 MG/ML / clavulanate 6.25...</td>\n",
              "      <td>RxNorm Extension</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>OMOP5208019</td>\n",
              "      <td>RxNorm Extension</td>\n",
              "      <td>36919422</td>\n",
              "      <td>0.8 ML adalimumab 50 MG/ML Injectable Solution...</td>\n",
              "      <td>RxNorm Extension</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>OMOP5185964</td>\n",
              "      <td>RxNorm Extension</td>\n",
              "      <td>36919439</td>\n",
              "      <td>ondansetron 8 MG Disintegrating Oral Tablet by...</td>\n",
              "      <td>RxNorm Extension</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>OMOP5191160</td>\n",
              "      <td>RxNorm Extension</td>\n",
              "      <td>36919440</td>\n",
              "      <td>tadalafil 10 MG Delayed Release Oral Tablet Bo...</td>\n",
              "      <td>RxNorm Extension</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-537d1ab0-0648-4260-8977-21efddb1e92c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-537d1ab0-0648-4260-8977-21efddb1e92c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-537d1ab0-0648-4260-8977-21efddb1e92c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-38d0a6b0-b8d0-4c14-afaa-1c64238cc123\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-38d0a6b0-b8d0-4c14-afaa-1c64238cc123')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-38d0a6b0-b8d0-4c14-afaa-1c64238cc123 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(f\\\"MIMIC co-occurrence pairs saved to \\\\u2192 {mimic_snomed_pairs_out_path}\\\")\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"concept_code_source\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"OMOP5212221\",\n          \"OMOP5191160\",\n          \"OMOP5208019\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vocabulary_id_source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"RxNorm Extension\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"concept_id_2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"36919391\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"concept_name_destination\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"100 ML amoxicillin 25 MG/ML / clavulanate 6.25 MG/ML Oral Suspension [Augmentin] by Mawdsley-Brooks\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vocabulary_id_destination\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"RxNorm Extension\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating MIMIC-to-SNOMED mapping...\n",
            "ICD10CM to SNOMED mapping entries: 129,908\n",
            "ICD codes in diagnoses: ['G3183' 'F0280' 'R441' ... 'O30093' 'V835XXA' 'O359XX2']\n",
            "Is 'A000' in icd_snomed_map_df? False\n",
            " 'A000' not found in icd_snomed_map_df.\n",
            "MIMIC diagnoses after SNOMED mapping: 218,769 rows\n",
            "MIMIC diagnoses (unique SNOMED per admission): 218,768 rows\n",
            "\n",
            "Extracting co-occurrence pairs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing admissions: 100%|██████████| 148363/148363 [00:23<00:00, 6338.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 97,033 co-occurrence pairs.\n",
            "MIMIC co-occurrence pairs saved to → mimic_snomed_pairs.tsv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from itertools import combinations\n",
        "import zipfile # Import zipfile\n",
        "import os      # Import os\n",
        "from tqdm import tqdm # For progress bar\n",
        "\n",
        "# 1. Load and Clean MIMIC-IV Diagnoses\n",
        "mimic_path = os.path.join(BASE_DRIVE_PATH, \"/content/drive/MyDrive/knowledgegraphdata/diagnoses_icd.csv.gz\")\n",
        "print(\"Loading MIMIC-IV diagnoses data...\")\n",
        "diagnoses = pd.read_csv(mimic_path, dtype=str)\n",
        "print(f\"Loaded: {diagnoses.shape[0]:,} rows \\u00d7 {diagnoses.shape[1]} columns\\n\")\n",
        "\n",
        "cols_to_keep = [\"subject_id\", \"hadm_id\", \"seq_num\", \"icd_code\", \"icd_version\"]\n",
        "diagnoses = diagnoses[cols_to_keep]\n",
        "\n",
        "before_filter = len(diagnoses)\n",
        "diagnoses = diagnoses[diagnoses[\"icd_version\"] == \"10\"]\n",
        "after_filter = len(diagnoses)\n",
        "print(f\"ICD-10 filter applied: {before_filter:,} \\u2192 {after_filter:,} rows\")\n",
        "\n",
        "before_clean = len(diagnoses)\n",
        "diagnoses = diagnoses.dropna(subset=[\"icd_code\"])\n",
        "diagnoses = diagnoses[diagnoses[\"icd_code\"].str.strip() != \"\"]\n",
        "after_clean = len(diagnoses)\n",
        "print(f\"Cleaned empty ICD codes: {before_clean:,} \\u2192 {after_clean:,} rows\")\n",
        "\n",
        "before_dedup = len(diagnoses)\n",
        "diagnoses.drop_duplicates(subset=[\"subject_id\", \"hadm_id\", \"icd_code\"], inplace=True)\n",
        "after_dedup = len(diagnoses)\n",
        "print(f\"Removed duplicates: {before_dedup - after_dedup:,}\")\n",
        "\n",
        "diagnoses.reset_index(drop=True, inplace=True)\n",
        "\n",
        "out_path = \"mimic_icd10_clean.csv\"\n",
        "diagnoses.to_csv(out_path, index=False)\n",
        "print(f\"\\nCleaned ICD-10 data saved \\u2192 {out_path}\")\n",
        "\n",
        "print(\"\\nSample of cleaned dataset:\")\n",
        "print(diagnoses.sample(min(10, len(diagnoses)), random_state=42).to_string(index=False))\n",
        "\n",
        "# 2. Extract ICD \\u2192 SNOMED CT Mapping from Athena\n",
        "print(\"\\nLoading OHDSI Athena vocabularies...\")\n",
        "\n",
        "# --- Load CSVs directly from ZIPs into memory ---\n",
        "zip_file_concept = os.path.join(BASE_DRIVE_PATH, \"/content/drive/MyDrive/knowledgegraphdata/CONCEPT.zip\")\n",
        "with zipfile.ZipFile(zip_file_concept, 'r') as zf:\n",
        "    with zf.open('CONCEPT.csv') as f:\n",
        "        concepts = pd.read_csv(f, sep=\"\\t\", dtype=str, low_memory=False)\n",
        "print(f\"Loaded CONCEPT.csv from {zip_file_concept}\")\n",
        "\n",
        "zip_file_rel = os.path.join(BASE_DRIVE_PATH, \"/content/drive/MyDrive/knowledgegraphdata/CONCEPT_RELATIONSHIP.zip\")\n",
        "with zipfile.ZipFile(zip_file_rel, 'r') as zf:\n",
        "    with zf.open('CONCEPT_RELATIONSHIP.csv') as f:\n",
        "        rels = pd.read_csv(f, sep=\"\\t\", dtype=str, low_memory=False)\n",
        "print(f\"Loaded CONCEPT_RELATIONSHIP.csv from {zip_file_rel}\")\n",
        "# ---------------------------------------------------\n",
        "\n",
        "# Ensure vocabulary_id is clean right after loading\n",
        "concepts['vocabulary_id'] = concepts['vocabulary_id'].str.strip()\n",
        "\n",
        "# Ensure relationship_id is clean right after loading\n",
        "rels['relationship_id'] = rels['relationship_id'].str.strip()\n",
        "\n",
        "print(f\"Concepts: {len(concepts):,} rows, Relationships: {len(rels):,} rows\")\n",
        "print(\"\\n--- Debug: concepts DataFrame head ---\")\n",
        "display(concepts.head())\n",
        "print(\"\\n--- Debug: rels DataFrame head ---\")\n",
        "display(rels.head())\n",
        "\n",
        "mapping = rels[rels[\"relationship_id\"].isin([\"Maps to\", \"Maps to value\"])]\n",
        "\n",
        "concepts_small = concepts[[\"concept_id\", \"concept_code\", \"concept_name\", \"vocabulary_id\"]]\n",
        "merged = (\n",
        "    mapping\n",
        "    .merge(concepts_small, left_on=\"concept_id_1\", right_on=\"concept_id\")\n",
        "    .merge(concepts_small, left_on=\"concept_id_2\", right_on=\"concept_id\", suffixes=('_source', '_destination'))\n",
        ")\n",
        "print(\"\\n--- Debug: merged DataFrame head (relevant columns) ---\")\n",
        "display(merged[[\"concept_code_source\", \"vocabulary_id_source\", \"concept_id_2\", \"concept_name_destination\", \"vocabulary_id_destination\"]].head())\n",
        "\n",
        "# 3. Create MIMIC-to-SNOMED mapping\n",
        "print(\"\\nCreating MIMIC-to-SNOMED mapping...\")\n",
        "# Filter mapping for ICD10CM source and SNOMED destination\n",
        "icd_snomed_map_df = merged[\n",
        "    (merged[\"vocabulary_id_source\"] == \"ICD10CM\") &\n",
        "    (merged[\"vocabulary_id_destination\"] == \"SNOMED\")\n",
        "]\n",
        "# Select and rename columns for clarity\n",
        "icd_snomed_map_df = icd_snomed_map_df[[\n",
        "    \"concept_code_source\", \"concept_id_2\", \"concept_name_destination\"\n",
        "]].rename(columns={\n",
        "    \"concept_code_source\": \"icd_code\",\n",
        "    \"concept_id_2\": \"snomed_concept_id\",\n",
        "    \"concept_name_destination\": \"snomed_concept_name\"\n",
        "}).drop_duplicates(subset=[\"icd_code\", \"snomed_concept_id\"])\n",
        "print(f\"ICD10CM to SNOMED mapping entries: {len(icd_snomed_map_df):,}\")\n",
        "\n",
        "# --- Debugging print statements ---\n",
        "print(f\"ICD codes in diagnoses: {diagnoses['icd_code'].unique()}\")\n",
        "print(f\"Is 'A000' in icd_snomed_map_df? {'A000' in icd_snomed_map_df['icd_code'].values}\")\n",
        "if 'A000' in icd_snomed_map_df['icd_code'].values:\n",
        "    print(\"Found 'A000' in icd_snomed_map_df. Sample entry:\")\n",
        "    print(icd_snomed_map_df[icd_snomed_map_df['icd_code'] == 'A000'].head().to_string(index=False))\n",
        "else:\n",
        "    print(\" 'A000' not found in icd_snomed_map_df.\")\n",
        "# -----------------------------------\n",
        "\n",
        "# Merge MIMIC diagnoses with SNOMED concepts\n",
        "diagnoses_snomed = diagnoses.merge(\n",
        "    icd_snomed_map_df,\n",
        "    on=\"icd_code\",\n",
        "    how=\"inner\" # Keep only diagnoses that can be mapped to SNOMED\n",
        ")\n",
        "print(f\"MIMIC diagnoses after SNOMED mapping: {len(diagnoses_snomed):,} rows\")\n",
        "diagnoses_snomed.dropna(subset=[\"snomed_concept_id\"], inplace=True)\n",
        "diagnoses_snomed.drop_duplicates(subset=[\"subject_id\", \"hadm_id\", \"snomed_concept_id\"], inplace=True)\n",
        "print(f\"MIMIC diagnoses (unique SNOMED per admission): {len(diagnoses_snomed):,} rows\")\n",
        "\n",
        "\n",
        "# 4. Extract Co-occurrence Pairs\n",
        "print(\"\\nExtracting co-occurrence pairs...\")\n",
        "co_occurrence_list = []\n",
        "# Group by admission and iterate\n",
        "for (subject_id, hadm_id), group in tqdm(diagnoses_snomed.groupby([\"subject_id\", \"hadm_id\"]), desc=\"Processing admissions\"):\n",
        "    snomed_codes = sorted(group[\"snomed_concept_id\"].unique().tolist())\n",
        "    snomed_names = {row[\"snomed_concept_id\"]: row[\"snomed_concept_name\"] for idx, row in group.iterrows()}\n",
        "\n",
        "    # Generate all unique pairs of SNOMED codes within this admission\n",
        "    for code1, code2 in combinations(snomed_codes, 2):\n",
        "        # Ensure consistent order for pairs\n",
        "        if code1 < code2:\n",
        "            co_occurrence_list.append({\n",
        "                \"sourceId\": code1,\n",
        "                \"source_term\": snomed_names.get(code1, \"UNKNOWN\"),\n",
        "                \"relation_term\": \"co_occurs_with\",\n",
        "                \"destinationId\": code2,\n",
        "                \"destination_term\": snomed_names.get(code2, \"UNKNOWN\")\n",
        "            })\n",
        "        else:\n",
        "             co_occurrence_list.append({\n",
        "                \"sourceId\": code2,\n",
        "                \"source_term\": snomed_names.get(code2, \"UNKNOWN\"),\n",
        "                \"relation_term\": \"co_occurs_with\",\n",
        "                \"destinationId\": code1,\n",
        "                \"destination_term\": snomed_names.get(code1, \"UNKNOWN\")\n",
        "            })\n",
        "\n",
        "\n",
        "# Create DataFrame from co-occurrence list\n",
        "mimic_snomed_pairs = pd.DataFrame(co_occurrence_list)\n",
        "\n",
        "# If no pairs are generated (e.g., due to limited placeholder data), create an empty df with correct columns\n",
        "if mimic_snomed_pairs.empty:\n",
        "    mimic_snomed_pairs = pd.DataFrame(columns=[\n",
        "        \"sourceId\", \"source_term\", \"relation_term\", \"destinationId\", \"destination_term\"\n",
        "    ])\n",
        "\n",
        "\n",
        "print(f\"Generated {len(mimic_snomed_pairs):,} co-occurrence pairs.\")\n",
        "\n",
        "# 5. Save the co-occurrence pairs\n",
        "mimic_snomed_pairs_out_path = \"mimic_snomed_pairs.tsv\"\n",
        "mimic_snomed_pairs.to_csv(mimic_snomed_pairs_out_path, sep=\"\\t\", index=False)\n",
        "print(f\"MIMIC co-occurrence pairs saved to \\u2192 {mimic_snomed_pairs_out_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjyVEl_6noGg",
        "outputId": "8739a560-983b-47a1-878a-8ca30709d0cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading input files...\n",
            "SNOMED relations: 7,161,452\n",
            "MIMIC co-occurrences: 97,033\n",
            "\n",
            "Merging datasets...\n",
            "Before merge: SNOMED=7,161,452, MIMIC=97,033\n",
            "After merge (combined): 7,258,485\n",
            "Duplicate removal: 7,258,485 → 1,299,286 (removed 5,959,199)\n",
            "\n",
            "Saving merged graph → {OUT_PATH}\n",
            "Merged relational graph saved: 1,299,286 rows\n"
          ]
        }
      ],
      "source": [
        "# Cell 5: Merge SNOMED and MIMIC (from merge_snomed_and_mimic.py)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "SNOMED_PATH = \"snomed_relations_full.tsv\"\n",
        "MIMIC_PATH  = \"mimic_snomed_pairs.tsv\"\n",
        "OUT_PATH    = \"merged_relations.tsv\"\n",
        "\n",
        "print(\"Loading input files...\")\n",
        "snomed_df = pd.read_csv(SNOMED_PATH, sep=\"\\t\", dtype=str)\n",
        "mimic_df  = pd.read_csv(MIMIC_PATH, sep=\"\\t\", dtype=str)\n",
        "print(f\"SNOMED relations: {len(snomed_df):,}\")\n",
        "print(f\"MIMIC co-occurrences: {len(mimic_df):,}\\n\")\n",
        "\n",
        "# === Normalize columns for consistency ===\n",
        "required_cols = [\"sourceId\", \"source_term\", \"relation_term\", \"destinationId\", \"destination_term\"]\n",
        "\n",
        "def ensure_cols(df, name):\n",
        "    missing = set(required_cols) - set(df.columns)\n",
        "    if missing:\n",
        "        raise ValueError(f\"{name} missing columns: {missing}\")\n",
        "    return df[required_cols].copy()\n",
        "\n",
        "snomed_df = ensure_cols(snomed_df, \"SNOMED\")\n",
        "mimic_df  = ensure_cols(mimic_df, \"MIMIC\")\n",
        "\n",
        "# === Add dataset source label (optional) ===\n",
        "snomed_df[\"source\"] = \"SNOMED_CT\"\n",
        "mimic_df[\"source\"]  = \"MIMIC_IV\"\n",
        "\n",
        "# === Merge ===\n",
        "print(\"Merging datasets...\")\n",
        "before_merge_snomed = len(snomed_df)\n",
        "before_merge_mimic  = len(mimic_df)\n",
        "merged = pd.concat([snomed_df, mimic_df], ignore_index=True)\n",
        "\n",
        "after_merge = len(merged)\n",
        "print(f\"Before merge: SNOMED={before_merge_snomed:,}, MIMIC={before_merge_mimic:,}\")\n",
        "print(f\"After merge (combined): {after_merge:,}\")\n",
        "\n",
        "# === Remove duplicates ===\n",
        "before_clean = len(merged)\n",
        "merged.drop_duplicates(subset=[\"sourceId\", \"relation_term\", \"destinationId\"], inplace=True)\n",
        "after_clean = len(merged)\n",
        "print(f\"Duplicate removal: {before_clean:,} → {after_clean:,} (removed {before_clean - after_clean:,})\")\n",
        "\n",
        "# === Summary ===\n",
        "print(\"\\nSaving merged graph → {OUT_PATH}\")\n",
        "merged.to_csv(OUT_PATH, sep=\"\\t\", index=False)\n",
        "print(f\"Merged relational graph saved: {len(merged):,} rows\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ozcPOGlnz-8",
        "outputId": "e9500a13-cdb4-4d01-c1be-541cfba9cd28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading merged dataset: merged_relations.tsv\n",
            "Loaded: 1,299,286 edges, 102 relation types\n",
            "Unique nodes: 382,356\n",
            "Base relation types: 102\n",
            "Total relations (including inverses): 204\n",
            "Total edges after adding inverses: 2,598,572\n",
            "Saved graph tensors → graph_data.pt\n",
            "Saved node map → node_id_map.csv\n",
            "Saved relation map → rel_id_map.csv\n",
            "\n",
            "Graph construction complete.\n",
            "Nodes: 382,356 | Relations: 204 | Edges: 2,598,572\n",
            "Train edges: 2078856, Val: 259856, Test: 259860\n"
          ]
        }
      ],
      "source": [
        "# Cell 6: Graph Tensor Creation and Splitting (from Dataset_creation.py)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from collections import defaultdict\n",
        "\n",
        "IN_PATH = \"merged_relations.tsv\"\n",
        "OUT_GRAPH = \"graph_data.pt\"\n",
        "OUT_NODEMAP = \"node_id_map.csv\"\n",
        "OUT_RELMAP = \"rel_id_map.csv\"\n",
        "\n",
        "SPLIT_RATIO = (0.8, 0.1, 0.1)   # train/val/test\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "print(f\"Loading merged dataset: {IN_PATH}\")\n",
        "df = pd.read_csv(IN_PATH, sep=\"\\t\", dtype=str)\n",
        "print(f\"Loaded: {len(df):,} edges, {df['relation_term'].nunique():,} relation types\")\n",
        "\n",
        "required_cols = [\"sourceId\", \"relation_term\", \"destinationId\"]\n",
        "for c in required_cols:\n",
        "    if c not in df.columns:\n",
        "        raise ValueError(f\"Missing column: {c}\")\n",
        "\n",
        "# 1. Clean and validate (redundant due to merge_snomed_and_mimic.py but kept for robustness)\n",
        "df = df.dropna(subset=required_cols)\n",
        "df = df[(df[\"sourceId\"].str.strip() != \"\") & (df[\"destinationId\"].str.strip() != \"\")]\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# 2. Create node index mapping\n",
        "nodes = pd.Index(pd.unique(pd.concat([df[\"sourceId\"], df[\"destinationId\"]], ignore_index=True)))\n",
        "node2id = {nid: i for i, nid in enumerate(nodes)}\n",
        "print(f\"Unique nodes: {len(node2id):,}\")\n",
        "\n",
        "# 3. Create relation index mapping\n",
        "base_relations = sorted(df[\"relation_term\"].unique().tolist())\n",
        "rel2id = {r: i for i, r in enumerate(base_relations)}\n",
        "print(f\"Base relation types: {len(rel2id)}\")\n",
        "\n",
        "# Encode edges\n",
        "src = df[\"sourceId\"].map(node2id).astype(np.int64).values\n",
        "dst = df[\"destinationId\"].map(node2id).astype(np.int64).values\n",
        "rel = df[\"relation_term\"].map(rel2id).astype(np.int64).values\n",
        "\n",
        "# 4. Add inverse relations\n",
        "inv_relations = [r + \"_inv\" for r in base_relations]\n",
        "inv_offset = len(rel2id)\n",
        "for i, r in enumerate(inv_relations):\n",
        "    rel2id[r] = inv_offset + i\n",
        "\n",
        "src_inv = dst.copy()\n",
        "dst_inv = src.copy()\n",
        "rel_inv = rel + inv_offset\n",
        "\n",
        "# Concatenate original + inverse\n",
        "src_all = np.concatenate([src, src_inv])\n",
        "dst_all = np.concatenate([dst, dst_inv])\n",
        "rel_all = np.concatenate([rel, rel_inv])\n",
        "\n",
        "num_nodes = len(node2id)\n",
        "num_relations = len(rel2id)\n",
        "print(f\"Total relations (including inverses): {num_relations}\")\n",
        "print(f\"Total edges after adding inverses: {len(src_all):,}\")\n",
        "\n",
        "# 5. Build PyTorch tensors\n",
        "edge_index = torch.tensor(np.vstack([src_all, dst_all]), dtype=torch.long)\n",
        "edge_type = torch.tensor(rel_all, dtype=torch.long)\n",
        "\n",
        "# 6. Train/Val/Test Split\n",
        "rng = np.random.default_rng(RANDOM_SEED)\n",
        "E = len(src)  # original (non-inverse) edges\n",
        "perm = rng.permutation(E)\n",
        "\n",
        "n_train = int(SPLIT_RATIO[0] * E)\n",
        "n_val = int(SPLIT_RATIO[1] * E)\n",
        "\n",
        "train_idx_base = perm[:n_train]\n",
        "val_idx_base = perm[n_train:n_train + n_val]\n",
        "test_idx_base = perm[n_train + n_val:]\n",
        "\n",
        "# Duplicate indices for inverse edges\n",
        "train_idx = np.concatenate([train_idx_base, train_idx_base + E])\n",
        "val_idx = np.concatenate([val_idx_base, val_idx_base + E])\n",
        "test_idx = np.concatenate([test_idx_base, test_idx_base + E])\n",
        "\n",
        "train_idx = torch.tensor(train_idx, dtype=torch.long)\n",
        "val_idx = torch.tensor(val_idx, dtype=torch.long)\n",
        "test_idx = torch.tensor(test_idx, dtype=torch.long)\n",
        "\n",
        "# 7. Save all outputs\n",
        "graph_data = {\n",
        "    \"num_nodes\": num_nodes,\n",
        "    \"num_relations\": num_relations,\n",
        "    \"edge_index\": edge_index,\n",
        "    \"edge_type\": edge_type,\n",
        "    \"train_idx\": train_idx,\n",
        "    \"val_idx\": val_idx,\n",
        "    \"test_idx\": test_idx,\n",
        "    \"node_ids\": list(nodes),\n",
        "    \"rel2id\": rel2id,\n",
        "    \"base_relations\": base_relations,\n",
        "}\n",
        "\n",
        "torch.save(graph_data, OUT_GRAPH)\n",
        "print(f\"Saved graph tensors → {OUT_GRAPH}\")\n",
        "\n",
        "# Save mappings for interpretability\n",
        "pd.DataFrame({\"node_index\": np.arange(num_nodes), \"concept_id\": list(nodes)}).to_csv(OUT_NODEMAP, index=False)\n",
        "pd.DataFrame({\"relation\": list(rel2id.keys()), \"rel_id\": list(rel2id.values())}).to_csv(OUT_RELMAP, index=False)\n",
        "print(f\"Saved node map → {OUT_NODEMAP}\")\n",
        "print(f\"Saved relation map → {OUT_RELMAP}\")\n",
        "\n",
        "print(\"\\nGraph construction complete.\")\n",
        "print(f\"Nodes: {num_nodes:,} | Relations: {num_relations:,} | Edges: {len(src_all):,}\")\n",
        "print(f\"Train edges: {len(train_idx)}, Val: {len(val_idx)}, Test: {len(test_idx)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "pEjoDK3Tn7oN",
        "outputId": "1b5b9a07-1c7c-466a-ab98-3d49c0d39786"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "\n",
            "--- PHASE 1: TransE Embedding Pre-training ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TransE Pre-training:   0%|          | 0/50 [00:00<?, ?it/s]/tmp/ipython-input-4158809868.py:209: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
            "Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)\n",
            "  total_loss += float(loss) * head_index.numel()\n",
            "TransE Pre-training:   8%|▊         | 4/50 [55:56<10:43:16, 839.05s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4158809868.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtail_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mpre_train_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhead_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m                             )\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    245\u001b[0m             )\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    248\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mmaybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdisabled_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    951\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 953\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    954\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[0m\n\u001b[1;32m    533\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import TransE\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- 1. Custom Classifier Module ---\n",
        "class AdaptedTransE(nn.Module):\n",
        "    def __init__(self, num_nodes, num_relations, embedding_dim, dropout_rate=0.3):\n",
        "        super().__init__()\n",
        "        self.num_nodes = num_nodes\n",
        "        self.num_relations = num_relations\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        # 1. Embedding Layer (TransE from PyG, for learning embeddings h and t)\n",
        "        # Note: We use this layer purely for its learned entity embeddings and batching utility.\n",
        "        # The TransE relation embeddings (e_r) are not used in the final classifier.\n",
        "        self.transe = TransE(\n",
        "            num_nodes=num_nodes,\n",
        "            num_relations=num_relations,\n",
        "            hidden_channels=embedding_dim,\n",
        "            margin=1.0,\n",
        "            p_norm=1.0,\n",
        "        )\n",
        "\n",
        "        # 2. Relation Classifier (Multi-Head Classifier as described in the paper)\n",
        "        # It takes the difference vector (h - t), which is a tensor of size [batch_size, embedding_dim].\n",
        "        # It maps this vector to the number of relation types.\n",
        "        self.classifier = nn.Sequential(\n",
        "            # First, normalize or use dropout on the difference vector (h - t)\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            # Linear layer to map the difference vector to logits for each relation type\n",
        "            nn.Linear(embedding_dim, num_relations)\n",
        "        )\n",
        "\n",
        "        # Initialize the classifier's weights (using Xavier for stability, as suggested for embeddings)\n",
        "        nn.init.xavier_uniform_(self.classifier[1].weight)\n",
        "\n",
        "    def forward(self, head_index, tail_index):\n",
        "        # 1. Get Normalized Entity Embeddings from the TransE layer\n",
        "        # The TransE model internally maintains normalized entity embeddings.\n",
        "        h = self.transe.node_emb(head_index)\n",
        "        t = self.transe.node_emb(tail_index)\n",
        "\n",
        "        # 2. Calculate the difference vector (h - t) which approximates the relation r\n",
        "        diff_vector = h - t\n",
        "\n",
        "        # 3. Pass the difference vector to the classifier head\n",
        "        logits = self.classifier(diff_vector)\n",
        "\n",
        "        return logits\n",
        "\n",
        "    # We will use the standard PyG TransE loss for pre-training the embeddings\n",
        "    def transe_loss(self, head_index, rel_type, tail_index):\n",
        "        return self.transe.loss(head_index, rel_type, tail_index)\n",
        "\n",
        "# --- 2. Training Function for the Classifier ---\n",
        "def train_classifier(model, optimizer, data_loader, edge_index, edge_type, base_relations, num_epochs):\n",
        "    model.train()\n",
        "\n",
        "    # We need to map the full edge_type tensor to only the base relations (non-inverse)\n",
        "    # to match the classifier's output size.\n",
        "    # We assume base relations are the first half of the total relations (as per Dataset_creation.py)\n",
        "    num_base_relations = len(base_relations)\n",
        "\n",
        "    # We only train on the forward (non-inverse) relationships.\n",
        "    forward_mask = edge_type < num_base_relations\n",
        "    forward_indices = torch.where(forward_mask)[0]\n",
        "\n",
        "    # Use only the training set indices for the forward relations\n",
        "    # `graph_data['train_idx']` is now guaranteed to be on the correct device\n",
        "    train_indices_forward = forward_indices[torch.isin(forward_indices, graph_data['train_idx'])]\n",
        "\n",
        "    # Create a new loader that iterates over the forward-only triples\n",
        "    classifier_loader = model.transe.loader(\n",
        "        head_index=edge_index[0, train_indices_forward],\n",
        "        rel_type=edge_type[train_indices_forward],\n",
        "        tail_index=edge_index[1, train_indices_forward],\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "    )\n",
        "\n",
        "    print(\"\\nStarting Adapted TransE Classifier Training...\")\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        total_loss = 0\n",
        "        correct_predictions = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        for head_index, rel_type, tail_index in classifier_loader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Predict the relation type using the classifier\n",
        "            logits = model(head_index, tail_index)\n",
        "\n",
        "            # Use Cross-Entropy Loss for multi-class classification\n",
        "            loss = F.cross_entropy(logits, rel_type)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * head_index.size(0)\n",
        "            total_samples += head_index.size(0)\n",
        "\n",
        "            # Calculate accuracy\n",
        "            _, predicted = torch.max(logits, 1)\n",
        "            correct_predictions += (predicted == rel_type).sum().item()\n",
        "\n",
        "        avg_loss = total_loss / total_samples\n",
        "        accuracy = correct_predictions / total_samples\n",
        "\n",
        "        print(f\"Epoch: {epoch:03d}, Loss: {avg_loss:.4f}, Train Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "        if epoch % 5 == 0 or epoch == num_epochs:\n",
        "            val_accuracy = evaluate_classifier(model, edge_index, edge_type, graph_data['val_idx'], num_base_relations)\n",
        "            print(f\"  >>> Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    # Final Test\n",
        "    test_accuracy = evaluate_classifier(model, edge_index, edge_type, graph_data['test_idx'], num_base_relations)\n",
        "    print(\"\\n--- FINAL CLASSIFIER TEST RESULTS ---\")\n",
        "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "    print(\"-------------------------------------\")\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_classifier(model, edge_index, edge_type, eval_idx, num_base_relations):\n",
        "    model.eval()\n",
        "\n",
        "    # Select only the forward (non-inverse) relations in the evaluation set\n",
        "    eval_mask = edge_type < num_base_relations\n",
        "    # `eval_idx` is now guaranteed to be on the correct device\n",
        "    eval_indices_forward = eval_idx[torch.isin(eval_idx, torch.where(eval_mask)[0])]\n",
        "\n",
        "    if eval_indices_forward.numel() == 0:\n",
        "        return 0.0\n",
        "\n",
        "    head_index = edge_index[0, eval_indices_forward]\n",
        "    tail_index = edge_index[1, eval_indices_forward]\n",
        "    rel_type = edge_type[eval_indices_forward]\n",
        "\n",
        "    logits = model(head_index, tail_index)\n",
        "    _, predicted = torch.max(logits, 1)\n",
        "\n",
        "    correct_predictions = (predicted == rel_type).sum().item()\n",
        "    total_samples = rel_type.size(0)\n",
        "\n",
        "    return correct_predictions / total_samples\n",
        "\n",
        "# --- 3. Main Execution (TransE Pre-training + Classifier Training) ---\n",
        "# --- Configuration (using paper's optimal values for the classifier part) ---\n",
        "EMBEDDING_DIM = 200      # Based on best run\n",
        "CLASSIFIER_LR = 0.001    # Learning rate for Adam\n",
        "CLASSIFIER_EPOCHS = 10   # Based on paper's finding\n",
        "PRE_TRAIN_EPOCHS = 50    # Pre-train longer than 10 for better embeddings\n",
        "BATCH_SIZE = 4096         # Based on best run\n",
        "\n",
        "GRAPH_DATA_PATH = \"graph_data.pt\"\n",
        "if not os.path.exists(GRAPH_DATA_PATH):\n",
        "    print(\"WARNING: graph_data.pt not found. Running placeholder data preparation now...\")\n",
        "    # This block requires running the data prep cells (1-6) first.\n",
        "    # Since they were provided in the prompt, we assume they have run or will run.\n",
        "    raise FileNotFoundError(\"Please ensure you run all cells prior to Cell 7, including the data preparation.\")\n",
        "\n",
        "graph_data = torch.load(GRAPH_DATA_PATH)\n",
        "\n",
        "# --- Prepare Tensors and Device ---\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "num_nodes = graph_data[\"num_nodes\"]\n",
        "num_relations = graph_data[\"num_relations\"]\n",
        "base_relations = graph_data[\"base_relations\"]\n",
        "\n",
        "# Move all relevant tensors to the device\n",
        "graph_data[\"edge_index\"] = graph_data[\"edge_index\"].to(device)\n",
        "graph_data[\"edge_type\"] = graph_data[\"edge_type\"].to(device)\n",
        "graph_data[\"train_idx\"] = graph_data[\"train_idx\"].to(device)\n",
        "graph_data[\"val_idx\"] = graph_data[\"val_idx\"].to(device)\n",
        "graph_data[\"test_idx\"] = graph_data[\"test_idx\"].to(device)\n",
        "\n",
        "edge_index = graph_data[\"edge_index\"]\n",
        "edge_type = graph_data[\"edge_type\"]\n",
        "\n",
        "# --- Initialize Model ---\n",
        "model = AdaptedTransE(num_nodes, num_relations, EMBEDDING_DIM).to(device)\n",
        "\n",
        "# --- PHASE 1: TransE Pre-training (Optimizing embeddings for link prediction) ---\n",
        "print(\"\\n--- PHASE 1: TransE Embedding Pre-training ---\")\n",
        "pre_train_optimizer = optim.Adam(model.transe.parameters(), lr=0.01) # Using standard KGE learning rate\n",
        "transe_loader = model.transe.loader(\n",
        "    head_index=edge_index[0],\n",
        "    rel_type=edge_type,\n",
        "    tail_index=edge_index[1],\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "for epoch in tqdm(range(1, PRE_TRAIN_EPOCHS + 1), desc=\"TransE Pre-training\"):\n",
        "    total_loss = 0\n",
        "    for head_index, rel_type, tail_index in transe_loader:\n",
        "        pre_train_optimizer.zero_grad()\n",
        "        loss = model.transe_loss(head_index, rel_type, tail_index)\n",
        "        loss.backward()\n",
        "        pre_train_optimizer.step()\n",
        "        total_loss += float(loss) * head_index.numel()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch:03d} Loss: {total_loss / edge_index.size(1):.4f}\")\n",
        "\n",
        "# --- PHASE 2: Relation Classification (Optimizing classifier on fixed embeddings) ---\n",
        "print(\"\\n--- PHASE 2: Relation Classification Training ---\")\n",
        "\n",
        "# Fix TransE embeddings and optimize only the classifier weights\n",
        "for param in model.transe.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "classifier_optimizer = optim.Adam(model.classifier.parameters(), lr=CLASSIFIER_LR)\n",
        "\n",
        "# Train the classifier using the forward-only data subset\n",
        "train_classifier(model, classifier_optimizer, None, edge_index, edge_type, base_relations, CLASSIFIER_EPOCHS)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39b23fbf"
      },
      "source": [
        "# Task\n",
        "## Explain Hits@10 and Link Prediction\n",
        "\n",
        "**Hits@10** is a metric commonly used in **link prediction** tasks for knowledge graphs. It measures how often the correct entity is ranked among the top `k` (e.g., 10) candidates when a missing entity in a triple is being predicted.\n",
        "\n",
        "In link prediction, the goal is to predict either the head entity (h), the relation (r), or the tail entity (t) of a triple `(h, r, t)` when one component is unknown. For example, given `(h, r, ?)` (predicting the tail entity), the model generates scores for all possible tail entities. Hits@10 then checks if the *true* tail entity for that triple is found among the top 10 highest-scoring candidates. A higher Hits@10 indicates better link prediction performance.\n",
        "\n",
        "**How it differs from classification accuracy:**\n",
        "\n",
        "The **classification accuracy** reported in the previous step (96.69%) was for **relation classification**. In that task, given a pair of head and tail entities `(h, ?, t)`, the model predicts the *type* of relation `r` that connects them. It's a multi-class classification problem where the model outputs probabilities (logits) for each possible relation type, and the accuracy is computed based on whether the highest-probability relation matches the true relation.\n",
        "\n",
        "In contrast, **link prediction** (and thus Hits@10) focuses on predicting *entities*, not relation types. It assesses how well the learned embeddings capture the structural relationships in the knowledge graph, allowing the model to \"fill in the blanks\" for missing entities. Both are important for evaluating knowledge graph embeddings but measure different aspects of the model's understanding of the graph.\n",
        "\n",
        "## Link Prediction Evaluation\n",
        "\n",
        "Now, let's implement and evaluate the Hits@10 metric for the pre-trained TransE embeddings.\n",
        "\n",
        "```python\n",
        "# Cell 8: Link Prediction Evaluation\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "# It's good practice to redefine the function if the agent restarts or if we want to run this cell independently.\n",
        "# However, for continuation, we can assume `model`, `graph_data`, `device` are available from the previous cell.\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_link_prediction(transe_model, edge_index, edge_type, eval_indices, k_values=[1, 3, 10], num_negatives=100):\n",
        "    \"\"\"\n",
        "    Evaluates link prediction performance using Hits@k and Mean Rank.\n",
        "\n",
        "    Args:\n",
        "        transe_model: The TransE model (e.g., model.transe) with trained embeddings.\n",
        "        edge_index: Tensor of shape [2, num_edges] representing head and tail indices.\n",
        "        edge_type: Tensor of shape [num_edges] representing relation types.\n",
        "        eval_indices: Indices for the evaluation set (e.g., test_idx).\n",
        "        k_values: List of k values for Hits@k.\n",
        "        num_negatives: Number of negative samples to generate for each positive triple.\n",
        "    Returns:\n",
        "        A dictionary containing Hits@k and Mean Rank metrics.\n",
        "    \"\"\"\n",
        "    transe_model.eval()\n",
        "\n",
        "    # Extract head, relation, tail for the evaluation triples\n",
        "    head_indices = edge_index[0, eval_indices]\n",
        "    rel_types = edge_type[eval_indices]\n",
        "    tail_indices = edge_index[1, eval_indices]\n",
        "\n",
        "    results = {}\n",
        "    print(f\"\\nPerforming link prediction evaluation on {len(eval_indices)} triples with {num_negatives} negative samples per triple...\")\n",
        "    \n",
        "    # PyG's k_hit function internally computes mean rank and Hits@k by corrupting\n",
        "    # both head and tail entities and averaging the results.\n",
        "    for k in k_values:\n",
        "        hits_at_k, mean_rank = transe_model.k_hit(\n",
        "            head_index=head_indices,\n",
        "            rel_type=rel_types,\n",
        "            tail_index=tail_indices,\n",
        "            k=k,\n",
        "            num_negatives=num_negatives,\n",
        "            batch_size=4096 # Use batching for k_hit to manage memory\n",
        "        )\n",
        "        results[f\"Hits@{k}\"] = hits_at_k\n",
        "        print(f\"  Hits@{k}: {hits_at_k:.4f}\")\n",
        "    \n",
        "    # Mean Rank is computed once for all k values by k_hit. We can just take one.\n",
        "    results[\"Mean Rank\"] = mean_rank\n",
        "    print(f\"  Mean Rank: {mean_rank:.4f}\")\n",
        "    return results\n",
        "\n",
        "# --- Call Link Prediction Evaluation after TransE Pre-training ---\n",
        "# The 'model' object contains the pre-trained TransE embeddings (model.transe)\n",
        "# from the previous training phase.\n",
        "\n",
        "print(\"\\n--- Evaluating Link Prediction on Test Set (after TransE Pre-training) ---\")\n",
        "link_pred_metrics = evaluate_link_prediction(\n",
        "    model.transe,\n",
        "    graph_data[\"edge_index\"],\n",
        "    graph_data[\"edge_type\"],\n",
        "    graph_data[\"test_idx\"], # Evaluate on the test set\n",
        "    k_values=[1, 3, 10]\n",
        ")\n",
        "print(\"-------------------------------------------------------\")\n",
        "print(\"Final Link Prediction Metrics (Test Set):\")\n",
        "for metric, value in link_pred_metrics.items():\n",
        "    print(f\"  {metric}: {value:.4f}\")\n",
        "print(\"-------------------------------------------------------\")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "746cd628"
      },
      "source": [
        "## Explain Hits@10 and Link Prediction\n",
        "\n",
        "### Subtask:\n",
        "Clarify what Hits@10 means in the context of knowledge graph embeddings and link prediction, and why it's different from the classification accuracy reported.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e155e80f"
      },
      "source": [
        "### Clarifying Hits@10 and Link Prediction vs. Classification Accuracy\n",
        "\n",
        "#### What is Link Prediction?\n",
        "\n",
        "Link prediction is a common task in knowledge graph analysis. It aims to predict missing links (relationships) between entities (nodes) in a knowledge graph. Given a triplet `(head_entity, relation, tail_entity)`, the goal is to:\n",
        "\n",
        "1.  **Predict a missing tail entity**: Given `(head_entity, relation, ?)`\n",
        "2.  **Predict a missing head entity**: Given `(?, relation, tail_entity)`\n",
        "3.  **(Less common for evaluation)** Predict a missing relation: Given `(head_entity, ?, tail_entity)`\n",
        "\n",
        "Link prediction models learn to embed entities and relations into a continuous vector space, such that the geometric relationships between these embeddings reflect the semantic relationships in the graph. For instance, in TransE-like models, if `(h, r, t)` is true, then `h + r ≈ t` in the embedding space.\n",
        "\n",
        "#### What is Hits@K?\n",
        "\n",
        "Hits@K is a common metric used to evaluate the performance of link prediction models. Specifically, it measures the proportion of *correctly predicted entities* (either head or tail) that appear within the top K ranked predictions. Here's how it works:\n",
        "\n",
        "1.  **Corrupting Triples**: For each true triple `(h, r, t)` in the test set, two corrupted versions are generated:\n",
        "    *   `(h, r, t')`: Replace the true tail `t` with a randomly chosen *incorrect* tail entity `t'`. This is repeated for many `t'` candidates.\n",
        "    *   `(h', r, t)`: Replace the true head `h` with a randomly chosen *incorrect* head entity `h'`. This is repeated for many `h'` candidates.\n",
        "\n",
        "2.  **Scoring and Ranking**: The link prediction model then scores how likely each corrupted triple is to be true. For example, in `(h, r, ?)`, the model would score `(h, r, e_i)` for *all* possible entities `e_i` in the graph. These scores are then ranked from most likely to least likely.\n",
        "\n",
        "3.  **Calculating Hits@K**: If the *true* missing entity (e.g., `t` in `(h, r, ?)`) is found among the top K highest-scoring predictions, it counts as a \"hit\".\n",
        "\n",
        "    *   **Hits@10** means that if the correct entity is found within the top 10 ranked predictions, it's counted as a hit. A higher Hits@10 score indicates a better model because it means the correct answer is frequently among the top plausible choices.\n",
        "\n",
        "#### How is Hits@10 Different from Classification Accuracy?\n",
        "\n",
        "The previous output from Cell 7 provided **Training Accuracy** and **Test Accuracy** for a **relation classification task**, which focused on predicting the *relation type* given a head and tail entity (or more specifically, the difference vector between head and tail embeddings).\n",
        "\n",
        "Here's the key distinction:\n",
        "\n",
        "*   **Relation Classification Accuracy**: Measures how well the model can identify the *correct relation type* `r` given a specific `(h, ?, t)` pair. The model predicts one of `num_base_relations` categories, and accuracy is simply `(correct_predictions / total_predictions)`. The output of the classifier is a probability distribution over relation types.\n",
        "\n",
        "*   **Hits@10 (Link Prediction)**: Measures how well the model can identify the *correct missing entity* (head or tail) given an `(h, r, ?)` or `(?, r, t)` pair. This is a much harder task, as the model has to rank the correct entity among *all possible entities* (hundreds of thousands in our case, `num_nodes`). The output is not a single classification, but a ranked list of entities.\n",
        "\n",
        "**Analogy**:\n",
        "\n",
        "*   **Relation Classification** is like being shown two people and asked, \"What is their relationship? (e.g., 'parent of', 'sibling of', 'friend of')\". You choose from a fixed, relatively small list of options.\n",
        "*   **Link Prediction with Hits@10** is like being told, \"This person is the 'parent of' someone. Who is it?\" and you have to pick the correct child from everyone in the world. Hits@10 asks if the correct child was among your top 10 guesses.\n",
        "\n",
        "**Why the difference in reported metrics?**\n",
        "\n",
        "*   The previous code built a **classifier** on top of the learned embeddings specifically to predict the `relation_term` given `(h, t)`. Its accuracy directly reflects how well it performs this *classification* task.\n",
        "*   To evaluate link prediction (predicting missing entities), one would typically use metrics like Hits@K, Mean Rank (MR), and Mean Reciprocal Rank (MRR). The current code *does not* perform a link prediction evaluation, so these metrics are not reported. The model's `transe.forward()` method is designed for scoring triples for link prediction, but the current training loop and evaluation functions are tailored for relation classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48fdec67"
      },
      "source": [
        "## Implement Link Prediction Evaluation Function\n",
        "\n",
        "### Subtask:\n",
        "Define the `evaluate_link_prediction` function to calculate Hits@k and Mean Rank.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2d2f519"
      },
      "source": [
        "**Reasoning**:\n",
        "To implement the link prediction evaluation function, I will define a Python function `evaluate_link_prediction` that takes the model, data, and a list of `k` values as input, and calculates Hits@k and Mean Rank. This function will utilize the `tqdm` library for progress indication and ensure computations are performed on the correct device (CPU/GPU).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04cfbcf1"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def evaluate_link_prediction(model, head_index, rel_type, tail_index, k_values=[1, 3, 10, 50, 100], batch_size=4096, device='cpu'):\n",
        "    model.eval() # Set model to evaluation mode\n",
        "\n",
        "    ranks = []\n",
        "    hits_at_k = {k: 0 for k in k_values}\n",
        "    num_samples = head_index.size(0)\n",
        "\n",
        "    # Create a data loader for evaluation to process in batches\n",
        "    eval_loader = model.transe.loader(\n",
        "        head_index=head_index,\n",
        "        rel_type=rel_type,\n",
        "        tail_index=tail_index,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "    )\n",
        "\n",
        "    with torch.no_grad(): # Disable gradient calculation for inference\n",
        "        for head, rel, tail in tqdm(eval_loader, desc=\"Evaluating Link Prediction\"):\n",
        "            head, rel, tail = head.to(device), rel.to(device), tail.to(device)\n",
        "\n",
        "            # For each (head, relation, tail) triple, we'll evaluate two tasks:\n",
        "            # 1. Predicting the tail entity given (head, relation)\n",
        "            # 2. Predicting the head entity given (relation, tail)\n",
        "\n",
        "            # --- Tail Prediction --- (corrupting tail)\n",
        "            # Generate corrupted triples: (head, relation, all_possible_tails)\n",
        "            all_nodes = torch.arange(model.num_nodes, device=device)\n",
        "            # Expand head and rel for broadcasting against all_nodes\n",
        "            b_head = head.unsqueeze(1).expand(-1, model.num_nodes)\n",
        "            b_rel = rel.unsqueeze(1).expand(-1, model.num_nodes)\n",
        "            b_tail_corrupted = all_nodes.unsqueeze(0).expand(head.size(0), -1)\n",
        "\n",
        "            # Calculate scores for all corrupted triples\n",
        "            # The score function is defined by the TransE model itself (distance)\n",
        "            # Lower distance is better, so we sort in ascending order\n",
        "            scores_tail_pred = model.transe.forward(b_head, b_rel, b_tail_corrupted).squeeze()\n",
        "\n",
        "            # Get the score of the true tail for each batch item\n",
        "            true_tail_scores = scores_tail_pred.gather(1, tail.unsqueeze(1)).squeeze()\n",
        "\n",
        "            # Calculate rank: count how many corrupted tails have a better (lower) score than the true tail\n",
        "            # Add 1 to convert from 0-indexed count to 1-indexed rank\n",
        "            ranks_tail_pred = (scores_tail_pred < true_tail_scores.unsqueeze(1)).sum(dim=1) + 1\n",
        "            ranks.extend(ranks_tail_pred.cpu().tolist())\n",
        "\n",
        "            # Calculate Hits@k for tail prediction\n",
        "            for k in k_values:\n",
        "                hits_at_k[k] += (ranks_tail_pred <= k).sum().item()\n",
        "\n",
        "            # --- Head Prediction --- (corrupting head)\n",
        "            # Generate corrupted triples: (all_possible_heads, relation, tail)\n",
        "            b_head_corrupted = all_nodes.unsqueeze(0).expand(head.size(0), -1)\n",
        "            b_rel = rel.unsqueeze(1).expand(-1, model.num_nodes)\n",
        "            b_tail = tail.unsqueeze(1).expand(-1, model.num_nodes)\n",
        "\n",
        "            # Calculate scores for all corrupted triples\n",
        "            scores_head_pred = model.transe.forward(b_head_corrupted, b_rel, b_tail).squeeze()\n",
        "\n",
        "            # Get the score of the true head for each batch item\n",
        "            true_head_scores = scores_head_pred.gather(1, head.unsqueeze(1)).squeeze()\n",
        "\n",
        "            # Calculate rank\n",
        "            ranks_head_pred = (scores_head_pred < true_head_scores.unsqueeze(1)).sum(dim=1) + 1\n",
        "            ranks.extend(ranks_head_pred.cpu().tolist())\n",
        "\n",
        "            # Calculate Hits@k for head prediction\n",
        "            for k in k_values:\n",
        "                hits_at_k[k] += (ranks_head_pred <= k).sum().item()\n",
        "\n",
        "    # Aggregate results\n",
        "    mean_rank = sum(ranks) / len(ranks)\n",
        "    for k in k_values:\n",
        "        hits_at_k[k] /= (num_samples * 2) # Multiply by 2 because we did head and tail prediction for each sample\n",
        "\n",
        "    results = {\"mean_rank\": mean_rank}\n",
        "    results.update({f\"hits_at_{k}\": hits_at_k[k] for k in k_values})\n",
        "\n",
        "    return results\n",
        "\n",
        "print(\"Defined evaluate_link_prediction function.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "085a6844"
      },
      "source": [
        "## Call Link Prediction Evaluation\n",
        "\n",
        "### Subtask:\n",
        "Integrate the newly created link prediction evaluation function into the main script to calculate and print the Hits@10 metric.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce9f85a8"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires calling the newly defined `evaluate_link_prediction` function and printing its results. This code block will execute the function on the test set and display the calculated Hits@k and Mean Rank.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4220c088"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import numpy as np # For random sampling\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_link_prediction(transe_model, edge_index, edge_type, eval_indices, k_values=[1, 3, 10], num_negatives=100, batch_size=4096):\n",
        "    \"\"\"\n",
        "    Evaluates link prediction performance using Hits@k and Mean Rank by manually\n",
        "    corrupting entities with negative sampling and ranking scores.\n",
        "\n",
        "    Args:\n",
        "        transe_model: The TransE model (e.g., model.transe) with trained embeddings.\n",
        "        edge_index: Tensor of shape [2, num_edges] representing head and tail indices.\n",
        "        edge_type: Tensor of shape [num_edges] representing relation types.\n",
        "        eval_indices: Indices for the evaluation set (e.g., test_idx).\n",
        "        k_values: List of k values for Hits@k.\n",
        "        num_negatives: Number of negative samples to generate for each positive triple.\n",
        "        batch_size: Batch size for processing evaluation triples.\n",
        "    Returns:\n",
        "        A dictionary containing Hits@k and Mean Rank metrics.\n",
        "    \"\"\"\n",
        "    transe_model.eval()\n",
        "    device = transe_model.node_emb.weight.device # Get the device from the model's embeddings\n",
        "\n",
        "    # Extract head, relation, tail for the evaluation triples\n",
        "    head_indices = edge_index[0, eval_indices]\n",
        "    rel_types = edge_type[eval_indices]\n",
        "    tail_indices = edge_index[1, eval_indices]\n",
        "\n",
        "    ranks = []\n",
        "    hits_at_k = {k: 0 for k in k_values}\n",
        "\n",
        "    num_eval_triples = head_indices.size(0)\n",
        "\n",
        "    # DataLoader for evaluation triples\n",
        "    eval_dataset = torch.utils.data.TensorDataset(head_indices, rel_types, tail_indices)\n",
        "    eval_loader = torch.utils.data.DataLoader(eval_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    print(f\"\\nPerforming link prediction evaluation on {num_eval_triples} triples with {num_negatives} negative samples per triple...\")\n",
        "\n",
        "    for h_batch, r_batch, t_batch in tqdm(eval_loader, desc=\"Evaluating Link Prediction\"):\n",
        "        h_batch, r_batch, t_batch = h_batch.to(device), r_batch.to(device), t_batch.to(device)\n",
        "\n",
        "        batch_size_actual = h_batch.size(0)\n",
        "        num_nodes = transe_model.num_nodes\n",
        "\n",
        "        # --- Tail Prediction ---\n",
        "        # Generate negative tails for each triple in the batch\n",
        "        # Ensure negative tails are not the true tail for each corresponding batch item\n",
        "        neg_tails = torch.randint(0, num_nodes, (batch_size_actual, num_negatives), device=device)\n",
        "        # For simplicity, if a negative happens to be the true tail, we keep it for now.\n",
        "        # A more rigorous implementation would re-sample until all are distinct from the true tail.\n",
        "\n",
        "        # Concatenate true tails and negative tails for ranking\n",
        "        # candidate_tails: [batch_size, 1 + num_negatives]\n",
        "        candidate_tails = torch.cat([t_batch.unsqueeze(1), neg_tails], dim=1)\n",
        "\n",
        "        # Expand h_batch and r_batch to match the number of candidates\n",
        "        # h_expanded: [batch_size, 1 + num_negatives]\n",
        "        # r_expanded: [batch_size, 1 + num_negatives]\n",
        "        h_expanded = h_batch.unsqueeze(1).expand(-1, 1 + num_negatives)\n",
        "        r_expanded = r_batch.unsqueeze(1).expand(-1, 1 + num_negatives)\n",
        "\n",
        "        # Score all candidate triples (h, r, candidate_t)\n",
        "        # scores: [batch_size, 1 + num_negatives]\n",
        "        scores = transe_model.forward(\n",
        "            h_expanded.reshape(-1),\n",
        "            r_expanded.reshape(-1),\n",
        "            candidate_tails.reshape(-1)\n",
        "        ).reshape(batch_size_actual, 1 + num_negatives)\n",
        "\n",
        "        # Rank the true tail (which is at index 0 in candidate_tails)\n",
        "        # Scores are distances, so lower is better. Sort in ascending order.\n",
        "        sorted_indices = torch.argsort(scores, dim=1) # indices of sorted scores\n",
        "\n",
        "        # Find rank of the true tail (which was the first candidate)\n",
        "        # The true rank is the position of index 0 in sorted_indices, plus 1 (1-based rank)\n",
        "        true_tail_rank = (sorted_indices == 0).nonzero(as_tuple=True)[1] + 1\n",
        "        ranks.extend(true_tail_rank.cpu().tolist()) # Collect ranks for Mean Rank\n",
        "\n",
        "        # Update Hits@k\n",
        "        for k in k_values:\n",
        "            hits_at_k[k] += (true_tail_rank <= k).sum().item()\n",
        "\n",
        "\n",
        "        # --- Head Prediction --- (symmetric logic)\n",
        "        # Generate negative heads for each triple in the batch\n",
        "        neg_heads = torch.randint(0, num_nodes, (batch_size_actual, num_negatives), device=device)\n",
        "\n",
        "        # Concatenate true heads and negative heads for ranking\n",
        "        candidate_heads = torch.cat([h_batch.unsqueeze(1), neg_heads], dim=1)\n",
        "\n",
        "        # Expand r_batch and t_batch to match the number of candidates\n",
        "        r_expanded = r_batch.unsqueeze(1).expand(-1, 1 + num_negatives)\n",
        "        t_expanded = t_batch.unsqueeze(1).expand(-1, 1 + num_negatives)\n",
        "\n",
        "        # Score all candidate triples (candidate_h, r, t)\n",
        "        scores = transe_model.forward(\n",
        "            candidate_heads.reshape(-1),\n",
        "            r_expanded.reshape(-1),\n",
        "            t_expanded.reshape(-1)\n",
        "        ).reshape(batch_size_actual, 1 + num_negatives)\n",
        "\n",
        "        # Rank the true head (which is at index 0 in candidate_heads)\n",
        "        sorted_indices = torch.argsort(scores, dim=1)\n",
        "        true_head_rank = (sorted_indices == 0).nonzero(as_tuple=True)[1] + 1\n",
        "        ranks.extend(true_head_rank.cpu().tolist()) # Collect ranks for Mean Rank\n",
        "\n",
        "        # Update Hits@k\n",
        "        for k in k_values:\n",
        "            hits_at_k[k] += (true_head_rank <= k).sum().item()\n",
        "\n",
        "    # Aggregate results\n",
        "    mean_rank = sum(ranks) / len(ranks) if len(ranks) > 0 else 0.0\n",
        "    total_evaluated_predictions = num_eval_triples * 2 # Each original sample leads to head and tail prediction\n",
        "\n",
        "    final_hits = {}\n",
        "    for k in k_values:\n",
        "        final_hits[f\"Hits@{k}\"] = hits_at_k[k] / total_evaluated_predictions\n",
        "\n",
        "    results = {\"Mean Rank\": mean_rank}\n",
        "    results.update(final_hits)\n",
        "\n",
        "    return results\n",
        "\n",
        "print(\"\\n--- Evaluating Link Prediction on Test Set ---\")\n",
        "link_pred_metrics = evaluate_link_prediction(\n",
        "    transe_model=model.transe, # Pass model.transe directly as it's the TransE instance\n",
        "    edge_index=graph_data[\"edge_index\"],\n",
        "    edge_type=graph_data[\"edge_type\"],\n",
        "    eval_indices=graph_data[\"test_idx\"], # Evaluate on the test set\n",
        "    k_values=[1, 3, 10],\n",
        "    num_negatives=100, # Use num_negatives for sampling\n",
        "    batch_size=BATCH_SIZE # Ensure BATCH_SIZE is accessible (it is in kernel state)\n",
        ")\n",
        "\n",
        "print(\"-------------------------------------------------------\")\n",
        "print(\"Final Link Prediction Metrics (Test Set):\")\n",
        "for metric, value in link_pred_metrics.items():\n",
        "    print(f\"  {metric}: {value:.4f}\")\n",
        "print(\"-------------------------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a1b3a59"
      },
      "source": [
        "# Task\n",
        "**Define AdaptedComplEx Model**: Create a new Python class `AdaptedComplEx` that inherits from `nn.Module`. This class will encapsulate `torch_geometric.nn.ComplEx` for embedding learning and add a multi-head classifier for relation classification. It will follow the same pattern as `AdaptedTransE`, ensuring the `forward` method produces logits for relation classification and a `complex_loss` method returns the ComplEx specific loss for pre-training embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "de3e36b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50062750-015c-4bbc-e465-e86869e6bbbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.12/dist-packages (2.7.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.13.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2025.11.12)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\n",
            "AdaptedComplEx class defined successfully.\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries if not already present\n",
        "!pip install torch_geometric\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import ComplEx\n",
        "\n",
        "\n",
        "class AdaptedComplEx(nn.Module):\n",
        "    def __init__(self, num_nodes, num_relations, embedding_dim, dropout_rate=0.3):\n",
        "        super().__init__()\n",
        "        self.num_nodes = num_nodes\n",
        "        self.num_relations = num_relations\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        # 1. Embedding Layer (ComplEx from PyG)\n",
        "        # ComplEx uses hidden_channels for the dimension of *each* part (real/imaginary).\n",
        "        # So, total embedding dimension for each node will be 2 * embedding_dim.\n",
        "        self.complex = ComplEx(\n",
        "            num_nodes=num_nodes,\n",
        "            num_relations=num_relations,\n",
        "            hidden_channels=embedding_dim, # This is the dimension for the real and imaginary parts separately\n",
        "            margin=1.0,\n",
        "        )\n",
        "\n",
        "        # 2. Relation Classifier (Multi-Head Classifier)\n",
        "        # It takes the difference vector (h - t), where h and t are the concatenated\n",
        "        # real and imaginary parts of the embeddings. Thus, input dimension is 2 * embedding_dim.\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Linear(2 * embedding_dim, num_relations) # ComplEx uses 2*embedding_dim for its node embeddings\n",
        "        )\n",
        "\n",
        "        # Initialize the classifier's weights\n",
        "        nn.init.xavier_uniform_(self.classifier[1].weight)\n",
        "\n",
        "    def forward(self, head_index, tail_index):\n",
        "        # 1. Get Entity Embeddings from the ComplEx layer\n",
        "        # ComplEx's node_emb returns embeddings that are already concatenated\n",
        "        # real and imaginary parts, effectively a 2*embedding_dim vector.\n",
        "        h = self.complex.node_emb(head_index)\n",
        "        t = self.complex.node_emb(tail_index)\n",
        "\n",
        "        # 2. Calculate the difference vector (h - t)\n",
        "        diff_vector = h - t\n",
        "\n",
        "        # 3. Pass the difference vector to the classifier head\n",
        "        logits = self.classifier(diff_vector)\n",
        "\n",
        "        return logits\n",
        "\n",
        "    # We will use the standard PyG ComplEx loss for pre-training the embeddings\n",
        "    def complex_loss(self, head_index, rel_type, tail_index):\n",
        "        return self.complex.loss(head_index, rel_type, tail_index)\n",
        "\n",
        "print(\"AdaptedComplEx class defined successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf39aad8"
      },
      "source": [
        "## Train AdaptedComplEx Model\n",
        "\n",
        "### Subtask:\n",
        "Implement the training procedure for the `AdaptedComplEx` model, including pre-training of ComplEx embeddings and training of the classifier head.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3787d31",
        "outputId": "0bf981df-ce8f-443a-ee50-4f0818ea9cfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "--- PHASE 1: ComplEx Embedding Pre-training ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ComplEx Pre-training:  20%|██        | 10/50 [01:50<07:20, 11.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 010 Loss: 0.0217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ComplEx Pre-training:  40%|████      | 20/50 [03:40<05:30, 11.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 020 Loss: 0.0147\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ComplEx Pre-training:  60%|██████    | 30/50 [05:30<03:40, 11.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 030 Loss: 0.0126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ComplEx Pre-training:  80%|████████  | 40/50 [07:20<01:50, 11.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 040 Loss: 0.0123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ComplEx Pre-training: 100%|██████████| 50/50 [09:10<00:00, 11.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 050 Loss: 0.0127\n",
            "\n",
            "--- PHASE 2: Relation Classification Training (AdaptedComplEx) ---\n",
            "\n",
            "Starting Adapted ComplEx Classifier Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, Loss: 4.2449, Train Accuracy: 0.2234\n",
            "Epoch: 002, Loss: 3.2637, Train Accuracy: 0.3767\n",
            "Epoch: 003, Loss: 3.0139, Train Accuracy: 0.4046\n",
            "Epoch: 004, Loss: 2.8115, Train Accuracy: 0.4208\n",
            "Epoch: 005, Loss: 2.6202, Train Accuracy: 0.4382\n",
            "  >>> Validation Accuracy: 0.5266\n",
            "Epoch: 006, Loss: 2.1802, Train Accuracy: 0.5292\n",
            "Epoch: 007, Loss: 2.0035, Train Accuracy: 0.5527\n",
            "Epoch: 008, Loss: 1.8443, Train Accuracy: 0.5841\n",
            "Epoch: 009, Loss: 1.6923, Train Accuracy: 0.6210\n",
            "Epoch: 010, Loss: 1.5497, Train Accuracy: 0.6612\n",
            "  >>> Validation Accuracy: 0.6818\n",
            "\n",
            "--- FINAL CLASSIFIER TEST RESULTS (AdaptedComplEx) ---\n",
            "Test Accuracy: 0.6789\n",
            "----------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import ComplEx\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# --- 1. Custom Classifier Module (Copied for completeness and independent execution)\n",
        "#      This was defined in the previous step, ensuring it's available.\n",
        "class AdaptedComplEx(nn.Module):\n",
        "    def __init__(self, num_nodes, num_relations, embedding_dim, dropout_rate=0.3):\n",
        "        super().__init__()\n",
        "        self.num_nodes = num_nodes\n",
        "        self.num_relations = num_relations\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        self.complex = ComplEx(\n",
        "            num_nodes=num_nodes,\n",
        "            num_relations=num_relations,\n",
        "            hidden_channels=embedding_dim,\n",
        "            # Removed 'margin=1.0' as ComplEx does not support it\n",
        "        )\n",
        "\n",
        "        # Based on the error, the ComplEx node embeddings are effectively `embedding_dim`,\n",
        "        # not `2 * embedding_dim` as initially assumed for the input to the classifier.\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Linear(embedding_dim, num_relations) # Changed from 2 * embedding_dim\n",
        "        )\n",
        "\n",
        "        nn.init.xavier_uniform_(self.classifier[1].weight)\n",
        "\n",
        "    def forward(self, head_index, tail_index):\n",
        "        h = self.complex.node_emb(head_index)\n",
        "        t = self.complex.node_emb(tail_index)\n",
        "\n",
        "        diff_vector = h - t\n",
        "\n",
        "        logits = self.classifier(diff_vector)\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def complex_loss(self, head_index, rel_type, tail_index):\n",
        "        return self.complex.loss(head_index, rel_type, tail_index)\n",
        "\n",
        "\n",
        "# --- 2. Training Function for the AdaptedComplEx Classifier ---\n",
        "def train_complex_classifier(model, optimizer, edge_index, edge_type, base_relations, num_epochs, batch_size, device):\n",
        "    model.train()\n",
        "    num_base_relations = len(base_relations)\n",
        "\n",
        "    # Filter for forward (non-inverse) relations in the training set\n",
        "    forward_mask = edge_type < num_base_relations\n",
        "    train_indices_forward = graph_data['train_idx'][torch.isin(graph_data['train_idx'], torch.where(forward_mask)[0])]\n",
        "\n",
        "    # Create a new loader that iterates over the forward-only triples in the training set\n",
        "    classifier_loader = model.complex.loader(\n",
        "        head_index=edge_index[0, train_indices_forward],\n",
        "        rel_type=edge_type[train_indices_forward],\n",
        "        tail_index=edge_index[1, train_indices_forward],\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "    )\n",
        "\n",
        "    print(\"\\nStarting Adapted ComplEx Classifier Training...\")\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        total_loss = 0\n",
        "        correct_predictions = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        for head_index, rel_type_batch, tail_index in classifier_loader:\n",
        "            head_index, rel_type_batch, tail_index = head_index.to(device), rel_type_batch.to(device), tail_index.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            logits = model(head_index, tail_index)\n",
        "            loss = F.cross_entropy(logits, rel_type_batch)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * head_index.size(0)\n",
        "            total_samples += head_index.size(0)\n",
        "\n",
        "            _, predicted = torch.max(logits, 1)\n",
        "            correct_predictions += (predicted == rel_type_batch).sum().item()\n",
        "\n",
        "        avg_loss = total_loss / total_samples\n",
        "        accuracy = correct_predictions / total_samples\n",
        "\n",
        "        print(f\"Epoch: {epoch:03d}, Loss: {avg_loss:.4f}, Train Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "        if epoch % 5 == 0 or epoch == num_epochs:\n",
        "            val_accuracy = evaluate_complex_classifier(model, edge_index, edge_type, graph_data['val_idx'], num_base_relations, device)\n",
        "            print(f\"  >>> Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "# --- 3. Evaluation Function for the AdaptedComplEx Classifier ---\n",
        "@torch.no_grad()\n",
        "def evaluate_complex_classifier(model, edge_index, edge_type, eval_idx, num_base_relations, device):\n",
        "    model.eval()\n",
        "\n",
        "    # Select only the forward (non-inverse) relations in the evaluation set\n",
        "    eval_mask = edge_type < num_base_relations\n",
        "    eval_indices_forward = eval_idx[torch.isin(eval_idx, torch.where(eval_mask)[0])]\n",
        "\n",
        "    if eval_indices_forward.numel() == 0:\n",
        "        return 0.0\n",
        "\n",
        "    head_index = edge_index[0, eval_indices_forward]\n",
        "    tail_index = edge_index[1, eval_indices_forward]\n",
        "    rel_type = edge_type[eval_indices_forward]\n",
        "\n",
        "    logits = model(head_index, tail_index)\n",
        "    _, predicted = torch.max(logits, 1)\n",
        "\n",
        "    correct_predictions = (predicted == rel_type).sum().item()\n",
        "    total_samples = rel_type.size(0)\n",
        "\n",
        "    return correct_predictions / total_samples\n",
        "\n",
        "\n",
        "# --- 4. Main Execution (ComplEx Pre-training + Classifier Training) ---\n",
        "# Configuration (ensure these are loaded from previous steps or defined)\n",
        "EMBEDDING_DIM = 200      # Example value\n",
        "CLASSIFIER_LR = 0.001    # Example value\n",
        "CLASSIFIER_EPOCHS = 10   # Example value\n",
        "PRE_TRAIN_EPOCHS = 50    # Example value\n",
        "BATCH_SIZE = 4096         # Example value\n",
        "GRAPH_DATA_PATH = \"graph_data.pt\" # Example path\n",
        "\n",
        "if not os.path.exists(GRAPH_DATA_PATH):\n",
        "    raise FileNotFoundError(f\"{GRAPH_DATA_PATH} not found. Please ensure data preparation is complete.\")\n",
        "\n",
        "graph_data = torch.load(GRAPH_DATA_PATH)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "num_nodes = graph_data[\"num_nodes\"]\n",
        "num_relations = graph_data[\"num_relations\"]\n",
        "base_relations = graph_data[\"base_relations\"]\n",
        "\n",
        "# Move all relevant tensors to the device\n",
        "graph_data[\"edge_index\"] = graph_data[\"edge_index\"].to(device)\n",
        "graph_data[\"edge_type\"] = graph_data[\"edge_type\"].to(device)\n",
        "graph_data[\"train_idx\"] = graph_data[\"train_idx\"].to(device)\n",
        "graph_data[\"val_idx\"] = graph_data[\"val_idx\"].to(device)\n",
        "graph_data[\"test_idx\"] = graph_data[\"test_idx\"].to(device)\n",
        "\n",
        "edge_index = graph_data[\"edge_index\"]\n",
        "edg_type = graph_data[\"edge_type\"]\n",
        "\n",
        "# Initialize AdaptedComplEx Model\n",
        "model_complex = AdaptedComplEx(num_nodes, num_relations, EMBEDDING_DIM).to(device)\n",
        "\n",
        "# --- PHASE 1: ComplEx Embedding Pre-training ---\n",
        "print(\"\\n--- PHASE 1: ComplEx Embedding Pre-training ---\")\n",
        "pre_train_optimizer_complex = optim.Adam(model_complex.complex.parameters(), lr=0.01)\n",
        "complex_loader = model_complex.complex.loader(\n",
        "    head_index=edge_index[0],\n",
        "    rel_type=edg_type,\n",
        "    tail_index=edge_index[1],\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "for epoch in tqdm(range(1, PRE_TRAIN_EPOCHS + 1), desc=\"ComplEx Pre-training\"):\n",
        "    total_loss = 0\n",
        "    for head_index, rel_type_batch, tail_index in complex_loader:\n",
        "        pre_train_optimizer_complex.zero_grad()\n",
        "        loss = model_complex.complex_loss(head_index.to(device), rel_type_batch.to(device), tail_index.to(device))\n",
        "        loss.backward()\n",
        "        pre_train_optimizer_complex.step()\n",
        "        total_loss += float(loss) * head_index.numel()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch:03d} Loss: {total_loss / edge_index.size(1):.4f}\")\n",
        "\n",
        "# --- PHASE 2: Relation Classification Training ---\n",
        "print(\"\\n--- PHASE 2: Relation Classification Training (AdaptedComplEx) ---\")\n",
        "\n",
        "# Freeze ComplEx embeddings\n",
        "for param in model_complex.complex.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "classifier_optimizer_complex = optim.Adam(model_complex.classifier.parameters(), lr=CLASSIFIER_LR)\n",
        "\n",
        "train_complex_classifier(model_complex, classifier_optimizer_complex, edge_index, edg_type, base_relations, CLASSIFIER_EPOCHS, BATCH_SIZE, device)\n",
        "\n",
        "# Final Test Accuracy\n",
        "test_accuracy_complex = evaluate_complex_classifier(model_complex, edge_index, edg_type, graph_data['test_idx'], len(base_relations), device)\n",
        "print(\"\\n--- FINAL CLASSIFIER TEST RESULTS (AdaptedComplEx) ---\")\n",
        "print(f\"Test Accuracy: {test_accuracy_complex:.4f}\")\n",
        "print(\"----------------------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1da5994"
      },
      "source": [
        "# Task\n",
        "Final Task: Evaluate the link prediction performance of the `AdaptedComplEx` model on the test set using Hits@k and Mean Rank metrics, and summarize the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e3bb1a1"
      },
      "source": [
        "## Define Link Prediction Evaluation Function for ComplEx\n",
        "\n",
        "### Subtask:\n",
        "Create a Python function `evaluate_link_prediction_complex` that takes the trained `ComplEx` embedding model, `edge_index`, `edge_type`, `eval_indices`, `k_values`, `num_negatives`, and `batch_size` as input to evaluate link prediction.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29740fad"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires defining a new function `evaluate_link_prediction_complex` that uses the `ComplEx` model's `k_hit` method to calculate link prediction metrics. This code block will implement that function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0806a2bf",
        "outputId": "ac72b408-0fe5-4a83-9c1c-da21776b541d"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_link_prediction_complex(complex_model, edge_index, edge_type, eval_indices, k_values=[1, 3, 10], num_negatives=100, batch_size=4096):\n",
        "    \"\"\"\n",
        "    Evaluates link prediction performance using Hits@k and Mean Rank for the ComplEx model.\n",
        "\n",
        "    Args:\n",
        "        complex_model: The ComplEx model instance (e.g., model_complex.complex).\n",
        "        edge_index: Tensor of shape [2, num_edges] representing head and tail indices.\n",
        "        edge_type: Tensor of shape [num_edges] representing relation types.\n",
        "        eval_indices: Indices for the evaluation set (e.g., test_idx).\n",
        "        k_values: List of k values for Hits@k.\n",
        "        num_negatives: Number of negative samples to generate for each positive triple.\n",
        "        batch_size: Batch size for processing evaluation triples.\n",
        "    Returns:\n",
        "        A dictionary containing Hits@k and Mean Rank metrics.\n",
        "    \"\"\"\n",
        "    complex_model.eval() # Set model to evaluation mode\n",
        "\n",
        "    # Extract head, relation, tail for the evaluation triples\n",
        "    head_indices = edge_index[0, eval_indices]\n",
        "    rel_types = edge_type[eval_indices]\n",
        "    tail_indices = edge_index[1, eval_indices]\n",
        "\n",
        "    results = {}\n",
        "    print(f\"\\nPerforming link prediction evaluation on {len(eval_indices)} triples with {num_negatives} negative samples per triple using ComplEx...\")\n",
        "\n",
        "    # PyG's k_hit function internally computes mean rank and Hits@k by corrupting\n",
        "    # both head and tail entities and averaging the results.\n",
        "    hits_at_k, mean_rank = complex_model.k_hit(\n",
        "        head_index=head_indices,\n",
        "        rel_type=rel_types,\n",
        "        tail_index=tail_indices,\n",
        "        k=k_values[-1], # k_hit expects a single k, it internally calculates for all k up to this value\n",
        "        num_negatives=num_negatives,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    # The k_hit function returns Hits@k for all specified k values in an internal list,\n",
        "    # and also the mean rank.\n",
        "    # We need to map the output to our k_values.\n",
        "    # The `k_hit` function returns a tensor of Hits@k values (indexed by k-1 for each k in k_values) and the mean rank.\n",
        "    # Let's assume hits_at_k is a tensor where hits_at_k[i] corresponds to Hits@k_values[i]\n",
        "\n",
        "    # For PyG's ComplEx k_hit, it returns one Hits@k value (for the k specified) and MR\n",
        "    # If k_hit changes behavior, this needs to be adjusted. For now, we will interpret the single k_hit output\n",
        "    # as the maximum k in k_values.\n",
        "\n",
        "    # Re-calling k_hit for each k for clarity based on typical PyG behavior\n",
        "    # A more efficient implementation might use a single call if PyG's k_hit returns all at once.\n",
        "    for k_val in k_values:\n",
        "        current_hits_at_k, current_mean_rank = complex_model.k_hit(\n",
        "            head_index=head_indices,\n",
        "            rel_type=rel_types,\n",
        "            tail_index=tail_indices,\n",
        "            k=k_val,\n",
        "            num_negatives=num_negatives,\n",
        "            batch_size=batch_size\n",
        "        )\n",
        "        results[f\"Hits@{k_val}\"] = current_hits_at_k.item() # .item() to get scalar from tensor\n",
        "        print(f\"  Hits@{k_val}: {results[f'Hits@{k_val}']:.4f}\")\n",
        "\n",
        "    # Mean Rank is computed with each k_hit call, but usually, we report one overall MR.\n",
        "    # We'll use the last computed mean rank for simplicity, or re-run k_hit for an overall MR if needed.\n",
        "    # A better approach would be to collect all ranks and compute MR once.\n",
        "    # For now, let's use the one from the largest k or if k_hit returns a single MR.\n",
        "    # Based on torch_geometric.nn.kge.k_hit, it returns one hits_at_k and one mean_rank.\n",
        "    # So we'll run it once for a representative k (e.g., k=10) to get the MR.\n",
        "\n",
        "    # Let's ensure we get one consistent Mean Rank\n",
        "    _, final_mean_rank = complex_model.k_hit(\n",
        "        head_index=head_indices,\n",
        "        rel_type=rel_types,\n",
        "        tail_index=tail_indices,\n",
        "        k=k_values[-1], # Use the largest k to get the mean rank\n",
        "        num_negatives=num_negatives,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "    results[\"Mean Rank\"] = final_mean_rank.item()\n",
        "    print(f\"  Mean Rank: {results['Mean Rank']:.4f}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "print(\"Defined evaluate_link_prediction_complex function.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined evaluate_link_prediction_complex function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "92fb9d67",
        "outputId": "8ad86a3c-557d-43fb-b94d-b11b1e7c2f6c"
      },
      "source": [
        "print(\"\\n--- Evaluating Link Prediction on Test Set (AdaptedComplEx) ---\")\n",
        "link_pred_metrics_complex = evaluate_link_prediction_complex(\n",
        "    complex_model=model_complex.complex, # Pass model_complex.complex directly\n",
        "    edge_index=graph_data[\"edge_index\"],\n",
        "    edge_type=graph_data[\"edge_type\"],\n",
        "    eval_indices=graph_data[\"test_idx\"], # Evaluate on the test set\n",
        "    k_values=[1, 3, 10],\n",
        "    num_negatives=100, # Use num_negatives for sampling\n",
        "    batch_size=BATCH_SIZE # Ensure BATCH_SIZE is accessible\n",
        ")\n",
        "\n",
        "print(\"-------------------------------------------------------\")\n",
        "print(\"Final Link Prediction Metrics (Test Set for ComplEx):\")\n",
        "for metric, value in link_pred_metrics_complex.items():\n",
        "    print(f\"  {metric}: {value:.4f}\")\n",
        "print(\"-------------------------------------------------------\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating Link Prediction on Test Set (AdaptedComplEx) ---\n",
            "\n",
            "Performing link prediction evaluation on 259860 triples with 100 negative samples per triple using ComplEx...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'ComplEx' object has no attribute 'k_hit'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2192699384.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n--- Evaluating Link Prediction on Test Set (AdaptedComplEx) ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m link_pred_metrics_complex = evaluate_link_prediction_complex(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mcomplex_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_complex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Pass model_complex.complex directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0medge_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"edge_index\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0medge_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"edge_type\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3121340621.py\u001b[0m in \u001b[0;36mevaluate_link_prediction_complex\u001b[0;34m(complex_model, edge_index, edge_type, eval_indices, k_values, num_negatives, batch_size)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# PyG's k_hit function internally computes mean rank and Hits@k by corrupting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# both head and tail entities and averaging the results.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     hits_at_k, mean_rank = complex_model.k_hit(\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mhead_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mrel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrel_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1962\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1964\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1965\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1966\u001b[0m         )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'ComplEx' object has no attribute 'k_hit'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6997c536"
      },
      "source": [
        "**Reasoning**:\n",
        "The error `AttributeError: 'ComplEx' object has no attribute 'k_hit'` indicates that the `torch_geometric.nn.ComplEx` class does not have a built-in `k_hit` method. I need to modify the `evaluate_link_prediction_complex` function to manually perform negative sampling, score calculation, and rank aggregation, similar to how the `evaluate_link_prediction` function for TransE was implemented.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65b539ec",
        "outputId": "ab6f411c-0e05-4783-f6ca-32272e76927f"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import numpy as np # Needed for random sampling\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_link_prediction_complex(complex_model, edge_index, edge_type, eval_indices, k_values=[1, 3, 10], num_negatives=100, batch_size=4096):\n",
        "    \"\"\"\n",
        "    Evaluates link prediction performance using Hits@k and Mean Rank for the ComplEx model\n",
        "    by manually corrupting entities with negative sampling and ranking scores.\n",
        "\n",
        "    Args:\n",
        "        complex_model: The ComplEx model instance (e.g., model_complex.complex).\n",
        "        edge_index: Tensor of shape [2, num_edges] representing head and tail indices.\n",
        "        edge_type: Tensor of shape [num_edges] representing relation types.\n",
        "        eval_indices: Indices for the evaluation set (e.g., test_idx).\n",
        "        k_values: List of k values for Hits@k.\n",
        "        num_negatives: Number of negative samples to generate for each positive triple.\n",
        "        batch_size: Batch size for processing evaluation triples.\n",
        "    Returns:\n",
        "        A dictionary containing Hits@k and Mean Rank metrics.\n",
        "    \"\"\"\n",
        "    complex_model.eval() # Set model to evaluation mode\n",
        "    device = complex_model.node_emb.weight.device # Get the device from the model's embeddings\n",
        "\n",
        "    # Extract head, relation, tail for the evaluation triples\n",
        "    head_indices = edge_index[0, eval_indices]\n",
        "    rel_types = edge_type[eval_indices]\n",
        "    tail_indices = edge_index[1, eval_indices]\n",
        "\n",
        "    ranks = []\n",
        "    hits_at_k = {k: 0 for k in k_values}\n",
        "\n",
        "    num_eval_triples = head_indices.size(0)\n",
        "    num_nodes = complex_model.num_nodes # Get total number of nodes from the model\n",
        "\n",
        "    # DataLoader for evaluation triples\n",
        "    eval_dataset = torch.utils.data.TensorDataset(head_indices, rel_types, tail_indices)\n",
        "    eval_loader = torch.utils.data.DataLoader(eval_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    print(f\"\\nPerforming link prediction evaluation on {num_eval_triples} triples with {num_negatives} negative samples per triple using ComplEx...\")\n",
        "\n",
        "    for h_batch, r_batch, t_batch in tqdm(eval_loader, desc=\"Evaluating Link Prediction\"):\n",
        "        h_batch, r_batch, t_batch = h_batch.to(device), r_batch.to(device), t_batch.to(device)\n",
        "\n",
        "        batch_size_actual = h_batch.size(0)\n",
        "\n",
        "        # --- Tail Prediction ---\n",
        "        # Generate negative tails for each triple in the batch\n",
        "        # For simplicity, negative samples might include the true tail, which is handled by ranking.\n",
        "        neg_tails = torch.randint(0, num_nodes, (batch_size_actual, num_negatives), device=device)\n",
        "\n",
        "        # Concatenate true tails and negative tails for ranking\n",
        "        # candidate_tails: [batch_size, 1 + num_negatives]\n",
        "        candidate_tails = torch.cat([t_batch.unsqueeze(1), neg_tails], dim=1)\n",
        "\n",
        "        # Expand h_batch and r_batch to match the number of candidates\n",
        "        h_expanded = h_batch.unsqueeze(1).expand(-1, 1 + num_negatives)\n",
        "        r_expanded = r_batch.unsqueeze(1).expand(-1, 1 + num_negatives)\n",
        "\n",
        "        # Score all candidate triples (h, r, candidate_t)\n",
        "        # scores: [batch_size, 1 + num_negatives]\n",
        "        scores = complex_model( # Use the forward method of ComplEx model for scoring\n",
        "            h_expanded.reshape(-1),\n",
        "            r_expanded.reshape(-1),\n",
        "            candidate_tails.reshape(-1)\n",
        "        ).reshape(batch_size_actual, 1 + num_negatives)\n",
        "\n",
        "        # Rank the true tail (which is at index 0 in candidate_tails)\n",
        "        # Scores are negative probabilities/likelihoods (ComplEx aims to maximize scores), so higher is better. Sort in descending order.\n",
        "        sorted_indices = torch.argsort(scores, dim=1, descending=True) # indices of sorted scores\n",
        "\n",
        "        # Find rank of the true tail (which was the first candidate)\n",
        "        true_tail_rank = (sorted_indices == 0).nonzero(as_tuple=True)[1] + 1\n",
        "        ranks.extend(true_tail_rank.cpu().tolist()) # Collect ranks for Mean Rank\n",
        "\n",
        "        # Update Hits@k\n",
        "        for k in k_values:\n",
        "            hits_at_k[k] += (true_tail_rank <= k).sum().item()\n",
        "\n",
        "\n",
        "        # --- Head Prediction --- (symmetric logic)\n",
        "        # Generate negative heads for each triple in the batch\n",
        "        neg_heads = torch.randint(0, num_nodes, (batch_size_actual, num_negatives), device=device)\n",
        "\n",
        "        # Concatenate true heads and negative heads for ranking\n",
        "        candidate_heads = torch.cat([h_batch.unsqueeze(1), neg_heads], dim=1)\n",
        "\n",
        "        # Expand r_batch and t_batch to match the number of candidates\n",
        "        r_expanded = r_batch.unsqueeze(1).expand(-1, 1 + num_negatives)\n",
        "        t_expanded = t_batch.unsqueeze(1).expand(-1, 1 + num_negatives)\n",
        "\n",
        "        # Score all candidate triples (candidate_h, r, t)\n",
        "        scores = complex_model( # Use the forward method of ComplEx model for scoring\n",
        "            candidate_heads.reshape(-1),\n",
        "            r_expanded.reshape(-1),\n",
        "            t_expanded.reshape(-1)\n",
        "        ).reshape(batch_size_actual, 1 + num_negatives)\n",
        "\n",
        "        # Rank the true head (which is at index 0 in candidate_heads)\n",
        "        sorted_indices = torch.argsort(scores, dim=1, descending=True)\n",
        "        true_head_rank = (sorted_indices == 0).nonzero(as_tuple=True)[1] + 1\n",
        "        ranks.extend(true_head_rank.cpu().tolist()) # Collect ranks for Mean Rank\n",
        "\n",
        "        # Update Hits@k\n",
        "        for k in k_values:\n",
        "            hits_at_k[k] += (true_head_rank <= k).sum().item()\n",
        "\n",
        "    # Aggregate results\n",
        "    mean_rank = sum(ranks) / len(ranks) if len(ranks) > 0 else 0.0\n",
        "    total_evaluated_predictions = num_eval_triples * 2 # Each original sample leads to head and tail prediction\n",
        "\n",
        "    final_hits = {}\n",
        "    for k in k_values:\n",
        "        final_hits[f\"Hits@{k}\"] = hits_at_k[k] / total_evaluated_predictions\n",
        "\n",
        "    results = {\"Mean Rank\": mean_rank}\n",
        "    results.update(final_hits)\n",
        "\n",
        "    return results\n",
        "\n",
        "print(\"Redefined evaluate_link_prediction_complex function with manual ranking.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Redefined evaluate_link_prediction_complex function with manual ranking.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a751dc5"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `evaluate_link_prediction_complex` function has been redefined to correctly handle link prediction evaluation for ComplEx, I will call this function to compute the Hits@k and Mean Rank metrics on the test set and print the summary results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5404acff",
        "outputId": "7cf28d8b-05a8-4bff-f99b-cdcce84c1b17"
      },
      "source": [
        "print(\"\\n--- Evaluating Link Prediction on Test Set (AdaptedComplEx) ---\")\n",
        "link_pred_metrics_complex = evaluate_link_prediction_complex(\n",
        "    complex_model=model_complex.complex, # Pass model_complex.complex directly\n",
        "    edge_index=graph_data[\"edge_index\"],\n",
        "    edge_type=graph_data[\"edge_type\"],\n",
        "    eval_indices=graph_data[\"test_idx\"], # Evaluate on the test set\n",
        "    k_values=[1, 3, 10],\n",
        "    num_negatives=100, # Use num_negatives for sampling\n",
        "    batch_size=BATCH_SIZE # Ensure BATCH_SIZE is accessible\n",
        ")\n",
        "\n",
        "print(\"-------------------------------------------------------\")\n",
        "print(\"Final Link Prediction Metrics (Test Set for ComplEx):\")\n",
        "for metric, value in link_pred_metrics_complex.items():\n",
        "    print(f\"  {metric}: {value:.4f}\")\n",
        "print(\"-------------------------------------------------------\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating Link Prediction on Test Set (AdaptedComplEx) ---\n",
            "\n",
            "Performing link prediction evaluation on 259860 triples with 100 negative samples per triple using ComplEx...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Link Prediction: 100%|██████████| 64/64 [00:05<00:00, 10.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Final Link Prediction Metrics (Test Set for ComplEx):\n",
            "  Mean Rank: 1.0714\n",
            "  Hits@1: 0.9624\n",
            "  Hits@3: 0.9928\n",
            "  Hits@10: 0.9999\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f2268ab"
      },
      "source": [
        "# Task\n",
        "Revise the `evaluate_link_prediction_complex` function to perform link prediction evaluation against all possible entities in the graph by scoring the true triple and all corrupted triples (where either the head or tail is replaced by every other entity in the graph) to determine the rank of the true entity. Then, re-evaluate the `AdaptedComplEx` model's link prediction performance using this revised function and display the new Hits@k and Mean Rank metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acced7c2"
      },
      "source": [
        "## Revise Link Prediction Evaluation Function\n",
        "\n",
        "### Subtask:\n",
        "Modify the `evaluate_link_prediction_complex` function to perform link prediction evaluation against *all* possible entities in the graph (i.e., all `num_nodes` entities).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d15e328"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires modifying the link prediction evaluation function to test against all possible entities. I will define a new `evaluate_link_prediction_complex` function that iterates through true triples, generates all `num_nodes` candidates in chunks, scores them using `complex_model.forward`, and then calculates ranks and Hits@k metrics based on these full rankings.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cdbbe22",
        "outputId": "14f4d6af-44ad-4186-93b4-d6ae64beae10"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_link_prediction_complex(complex_model, edge_index, edge_type, eval_indices, k_values=[1, 3, 10], batch_size_true_triples=1, max_candidate_batch_size=1024):\n",
        "    \"\"\"\n",
        "    Evaluates link prediction performance for the ComplEx model against all possible entities\n",
        "    in the graph, by processing candidate entities in chunks to manage memory.\n",
        "\n",
        "    Args:\n",
        "        complex_model: The ComplEx model instance (e.g., model_complex.complex).\n",
        "        edge_index: Tensor of shape [2, num_edges] representing head and tail indices.\n",
        "        edge_type: Tensor of shape [num_edges] representing relation types.\n",
        "        eval_indices: Indices for the evaluation set (e.g., test_idx).\n",
        "        k_values: List of k values for Hits@k.\n",
        "        batch_size_true_triples: Number of true triples to process at once. Recommended 1.\n",
        "        max_candidate_batch_size: Max number of candidate entities to score at once to manage memory.\n",
        "    Returns:\n",
        "        A dictionary containing Hits@k and Mean Rank metrics.\n",
        "    \"\"\"\n",
        "    complex_model.eval() # Set model to evaluation mode\n",
        "    device = complex_model.node_emb.weight.device # Get the device from the model's embeddings\n",
        "\n",
        "    # Extract head, relation, tail for the evaluation triples\n",
        "    head_indices = edge_index[0, eval_indices]\n",
        "    rel_types = edge_type[eval_indices]\n",
        "    tail_indices = edge_index[1, eval_indices]\n",
        "\n",
        "    ranks = []\n",
        "    hits_at_k = {k: 0 for k in k_values}\n",
        "\n",
        "    num_eval_triples = head_indices.size(0)\n",
        "    num_nodes = complex_model.num_nodes # Get total number of nodes from the model\n",
        "    all_nodes = torch.arange(num_nodes, device=device)\n",
        "\n",
        "    # DataLoader for evaluation triples, processing one true triple at a time\n",
        "    eval_dataset = torch.utils.data.TensorDataset(head_indices, rel_types, tail_indices)\n",
        "    eval_loader = torch.utils.data.DataLoader(eval_dataset, batch_size=batch_size_true_triples, shuffle=False)\n",
        "\n",
        "    print(f\"\\nPerforming link prediction evaluation on {num_eval_triples} triples (against all {num_nodes} entities per triple) using ComplEx...\")\n",
        "\n",
        "    for h_true_batch, r_true_batch, t_true_batch in tqdm(eval_loader, desc=\"Evaluating Link Prediction (all candidates)\"):\n",
        "        h_true = h_true_batch.squeeze(0) # Get single true head\n",
        "        r_true = r_true_batch.squeeze(0) # Get single true relation\n",
        "        t_true = t_true_batch.squeeze(0) # Get single true tail\n",
        "\n",
        "        # --- Tail Prediction: Evaluate (h_true, r_true, ?) ---\n",
        "        all_tail_scores = []\n",
        "        for i in range(0, num_nodes, max_candidate_batch_size):\n",
        "            candidate_tails_chunk = all_nodes[i : i + max_candidate_batch_size]\n",
        "\n",
        "            # Expand true head and relation for the chunk of candidate tails\n",
        "            h_expanded = h_true.expand_as(candidate_tails_chunk)\n",
        "            r_expanded = r_true.expand_as(candidate_tails_chunk)\n",
        "\n",
        "            # Score the chunk of candidate triples (h_true, r_true, candidate_tail)\n",
        "            scores_chunk = complex_model(h_expanded, r_expanded, candidate_tails_chunk)\n",
        "            all_tail_scores.append(scores_chunk)\n",
        "\n",
        "        # Concatenate scores for all candidates and find rank of the true tail\n",
        "        scores_all_tails = torch.cat(all_tail_scores)\n",
        "        # ComplEx maximizes scores, so rank is determined by how many candidates have a higher score\n",
        "        rank_t = (scores_all_tails > scores_all_tails[t_true]).sum().item() + 1\n",
        "        ranks.append(rank_t)\n",
        "        for k in k_values:\n",
        "            if rank_t <= k:\n",
        "                hits_at_k[k] += 1\n",
        "\n",
        "        # --- Head Prediction: Evaluate (?, r_true, t_true) ---\n",
        "        all_head_scores = []\n",
        "        for i in range(0, num_nodes, max_candidate_batch_size):\n",
        "            candidate_heads_chunk = all_nodes[i : i + max_candidate_batch_size]\n",
        "\n",
        "            # Expand true relation and tail for the chunk of candidate heads\n",
        "            r_expanded = r_true.expand_as(candidate_heads_chunk)\n",
        "            t_expanded = t_true.expand_as(candidate_heads_chunk)\n",
        "\n",
        "            # Score the chunk of candidate triples (candidate_head, r_true, t_true)\n",
        "            scores_chunk = complex_model(candidate_heads_chunk, r_expanded, t_expanded)\n",
        "            all_head_scores.append(scores_chunk)\n",
        "\n",
        "        # Concatenate scores for all candidates and find rank of the true head\n",
        "        scores_all_heads = torch.cat(all_head_scores)\n",
        "        rank_h = (scores_all_heads > scores_all_heads[h_true]).sum().item() + 1\n",
        "        ranks.append(rank_h)\n",
        "        for k in k_values:\n",
        "            if rank_h <= k:\n",
        "                hits_at_k[k] += 1\n",
        "\n",
        "    # Aggregate results\n",
        "    mean_rank = sum(ranks) / len(ranks) if len(ranks) > 0 else 0.0\n",
        "    total_evaluated_predictions = num_eval_triples * 2 # Each original sample leads to head and tail prediction\n",
        "\n",
        "    final_hits = {}\n",
        "    for k in k_values:\n",
        "        final_hits[f\"Hits@{k}\"] = hits_at_k[k] / total_evaluated_predictions\n",
        "\n",
        "    results = {\"Mean Rank\": mean_rank}\n",
        "    results.update(final_hits)\n",
        "\n",
        "    return results\n",
        "\n",
        "print(\"Defined evaluate_link_prediction_complex function for evaluation against all entities.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined evaluate_link_prediction_complex function for evaluation against all entities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efa51cd7"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `evaluate_link_prediction_complex` function has been redefined to correctly handle link prediction evaluation for ComplEx against all possible entities, I will call this function to compute the Hits@k and Mean Rank metrics on the test set and print the summary results.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}